{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 112017,
          "databundleVersionId": 13778912,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Training_model",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manoprasad2006/kaagle-comp1/blob/main/Training_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "vcs9gHw6sKLT"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "rice_pistachio_and_grapevine_leaf_classification_path = kagglehub.competition_download('rice-pistachio-and-grapevine-leaf-classification')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "m_TS0WPesKLY"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import psutil\n",
        "import logging\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:18:55.95817Z",
          "iopub.execute_input": "2025-09-27T15:18:55.958736Z",
          "iopub.status.idle": "2025-09-27T15:18:55.963961Z",
          "shell.execute_reply.started": "2025-09-27T15:18:55.958713Z",
          "shell.execute_reply": "2025-09-27T15:18:55.963236Z"
        },
        "id": "7DISltkvsKLa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:13:49.308352Z",
          "iopub.execute_input": "2025-09-27T15:13:49.309062Z",
          "iopub.status.idle": "2025-09-27T15:13:49.375293Z",
          "shell.execute_reply.started": "2025-09-27T15:13:49.309036Z",
          "shell.execute_reply": "2025-09-27T15:13:49.374568Z"
        },
        "id": "FS5ubJRasKLa",
        "outputId": "17b59ae0-a6cc-434b-fc74-4745580ff829"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Using device: cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, weight=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.weight = weight\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, weight=self.weight, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "        return focal_loss.mean()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:13:50.403292Z",
          "iopub.execute_input": "2025-09-27T15:13:50.404013Z",
          "iopub.status.idle": "2025-09-27T15:13:50.408635Z",
          "shell.execute_reply.started": "2025-09-27T15:13:50.403987Z",
          "shell.execute_reply": "2025-09-27T15:13:50.40782Z"
        },
        "id": "eLpx_85jsKLd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def mixup_data(x, y, alpha=1.0):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:13:51.462869Z",
          "iopub.execute_input": "2025-09-27T15:13:51.463586Z",
          "iopub.status.idle": "2025-09-27T15:13:51.46855Z",
          "shell.execute_reply.started": "2025-09-27T15:13:51.463554Z",
          "shell.execute_reply": "2025-09-27T15:13:51.467693Z"
        },
        "id": "Mt9ceQGGsKLd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_logging():\n",
        "    log_filename = f\"training_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_filename),\n",
        "            logging.StreamHandler()\n",
        "        ]\n",
        "    )\n",
        "    return logging.getLogger(__name__)\n",
        "\n",
        "logger = setup_logging()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:13:53.278019Z",
          "iopub.execute_input": "2025-09-27T15:13:53.27874Z",
          "iopub.status.idle": "2025-09-27T15:13:53.283173Z",
          "shell.execute_reply.started": "2025-09-27T15:13:53.278715Z",
          "shell.execute_reply": "2025-09-27T15:13:53.282478Z"
        },
        "id": "aOmbPjHTsKLe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    BATCH_SIZE = 28  # Optimized batch size\n",
        "    EPOCHS = 18      # Sweet spot for convergence\n",
        "    LEARNING_RATE = 2e-4  # Better learning rate\n",
        "    IMG_SIZE = 256   # Larger images for better detail\n",
        "    NUM_CLASSES = 20\n",
        "    NUM_FOLDS = 4    # 4 folds for balance of performance vs time\n",
        "    N_SPLITS = NUM_FOLDS\n",
        "    SEED = 42\n",
        "\n",
        "    SAVE_EVERY_EPOCH = False\n",
        "    SAVE_EVERY_N_BATCHES = 300\n",
        "    CHECKPOINT_DIR = \"checkpoints\"\n",
        "    MAX_MEMORY_PERCENT = 90\n",
        "    PATIENCE = 6  # Balanced patience\n",
        "\n",
        "    RESUME_FROM_CHECKPOINT = False\n",
        "    AUTO_REDUCE_BATCH_ON_OOM = True\n",
        "    MIN_BATCH_SIZE = 8"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:13:54.678153Z",
          "iopub.execute_input": "2025-09-27T15:13:54.67843Z",
          "iopub.status.idle": "2025-09-27T15:13:54.682698Z",
          "shell.execute_reply.started": "2025-09-27T15:13:54.678409Z",
          "shell.execute_reply": "2025-09-27T15:13:54.682055Z"
        },
        "id": "n-7EsfU8sKLe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(Config.CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "torch.manual_seed(Config.SEED)\n",
        "np.random.seed(Config.SEED)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:13:56.698197Z",
          "iopub.execute_input": "2025-09-27T15:13:56.69894Z",
          "iopub.status.idle": "2025-09-27T15:13:56.707963Z",
          "shell.execute_reply.started": "2025-09-27T15:13:56.698916Z",
          "shell.execute_reply": "2025-09-27T15:13:56.707325Z"
        },
        "id": "xbDVP7iksKLf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanup_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:13:57.884026Z",
          "iopub.execute_input": "2025-09-27T15:13:57.884277Z",
          "iopub.status.idle": "2025-09-27T15:13:57.887978Z",
          "shell.execute_reply.started": "2025-09-27T15:13:57.88426Z",
          "shell.execute_reply": "2025-09-27T15:13:57.887317Z"
        },
        "id": "vrlP-OnKsKLf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, scheduler, epoch, fold, batch_idx, loss, filepath):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'fold': fold,\n",
        "        'batch_idx': batch_idx,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "        'loss': loss,\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'memory_usage': psutil.virtual_memory().percent,\n",
        "        'config': {\n",
        "            'batch_size': Config.BATCH_SIZE,\n",
        "            'learning_rate': Config.LEARNING_RATE,\n",
        "            'img_size': Config.IMG_SIZE\n",
        "        }\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        torch.save(checkpoint, filepath)\n",
        "        print(f\"Checkpoint saved: {filepath}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to save checkpoint: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:13:59.625367Z",
          "iopub.execute_input": "2025-09-27T15:13:59.625676Z",
          "iopub.status.idle": "2025-09-27T15:13:59.631048Z",
          "shell.execute_reply.started": "2025-09-27T15:13:59.625653Z",
          "shell.execute_reply": "2025-09-27T15:13:59.630415Z"
        },
        "id": "n0vjyll-sKLg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class AgriculturalDataset(Dataset):\n",
        "\n",
        "    def __init__(self, image_paths, labels=None, transforms=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            image_path = self.image_paths[idx]\n",
        "\n",
        "            # Load image with error handling\n",
        "            if not os.path.exists(image_path):\n",
        "                print(f\"Image not found: {image_path}\")\n",
        "                # Return a black image as fallback\n",
        "                image = np.zeros((Config.IMG_SIZE, Config.IMG_SIZE, 3), dtype=np.uint8)\n",
        "            else:\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is None:\n",
        "                    print(f\"Failed to load image: {image_path}\")\n",
        "                    image = np.zeros((Config.IMG_SIZE, Config.IMG_SIZE, 3), dtype=np.uint8)\n",
        "                else:\n",
        "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            if self.transforms:\n",
        "                augmented = self.transforms(image=image)\n",
        "                image = augmented['image']\n",
        "\n",
        "            if self.labels is not None:\n",
        "                label = self.labels[idx]\n",
        "                return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "            return image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {idx}: {e}\")\n",
        "            # Return fallback data\n",
        "            fallback_image = torch.zeros((3, Config.IMG_SIZE, Config.IMG_SIZE))\n",
        "            if self.labels is not None:\n",
        "                return fallback_image, torch.tensor(0, dtype=torch.long)\n",
        "            return fallback_image"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:14:01.140812Z",
          "iopub.execute_input": "2025-09-27T15:14:01.141371Z",
          "iopub.status.idle": "2025-09-27T15:14:01.148298Z",
          "shell.execute_reply.started": "2025-09-27T15:14:01.14135Z",
          "shell.execute_reply": "2025-09-27T15:14:01.147561Z"
        },
        "id": "aIcWktRQsKLg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms(phase='train'):\n",
        "    if phase == 'train':\n",
        "        return A.Compose([\n",
        "            A.OneOf([\n",
        "                A.Resize(Config.IMG_SIZE, Config.IMG_SIZE),\n",
        "                A.Resize(Config.IMG_SIZE + 32, Config.IMG_SIZE + 32),\n",
        "            ], p=1.0),\n",
        "            A.RandomCrop(Config.IMG_SIZE, Config.IMG_SIZE),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.3),\n",
        "            A.RandomRotate90(p=0.5),\n",
        "            A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.15, rotate_limit=25, p=0.7),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
        "            A.HueSaturationValue(hue_shift_limit=25, sat_shift_limit=35, val_shift_limit=25, p=0.6),\n",
        "            A.OneOf([\n",
        "                A.GaussNoise(var_limit=(10.0, 50.0)),\n",
        "                A.GaussianBlur(blur_limit=3),\n",
        "                A.MotionBlur(blur_limit=3),\n",
        "            ], p=0.4),\n",
        "            A.CoarseDropout(max_holes=6, max_height=24, max_width=24, p=0.4),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(Config.IMG_SIZE, Config.IMG_SIZE),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:14:03.358278Z",
          "iopub.execute_input": "2025-09-27T15:14:03.35902Z",
          "iopub.status.idle": "2025-09-27T15:14:03.365158Z",
          "shell.execute_reply.started": "2025-09-27T15:14:03.358996Z",
          "shell.execute_reply": "2025-09-27T15:14:03.364448Z"
        },
        "id": "ennKkhHFsKLg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=Config.NUM_CLASSES, pretrained=True):\n",
        "        super(ResNetClassifier, self).__init__()\n",
        "\n",
        "        # Use ResNet101 for better feature extraction\n",
        "        self.backbone = models.resnet101(pretrained=pretrained)\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        # Attention mechanism for better feature selection\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, 2048),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Enhanced classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        # Apply attention mechanism\n",
        "        attention_weights = self.attention(features)\n",
        "        attended_features = features * attention_weights\n",
        "\n",
        "        output = self.classifier(attended_features)\n",
        "        return output, attended_features"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:14:05.121183Z",
          "iopub.execute_input": "2025-09-27T15:14:05.121868Z",
          "iopub.status.idle": "2025-09-27T15:14:05.128417Z",
          "shell.execute_reply.started": "2025-09-27T15:14:05.121843Z",
          "shell.execute_reply": "2025-09-27T15:14:05.127563Z"
        },
        "id": "M-_8AQnXsKLh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(train_dir, test_dir, train_labels_file='/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train.csv'):\n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "\n",
        "    print(\"Loading training data...\")\n",
        "\n",
        "    # Load training data with labels file\n",
        "    if train_labels_file and os.path.exists(train_labels_file):\n",
        "        try:\n",
        "            labels_df = pd.read_csv(train_labels_file)\n",
        "            label_dict = dict(zip(labels_df['ID'], labels_df['TARGET']))\n",
        "\n",
        "            for img_name in os.listdir(train_dir):\n",
        "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    img_path = os.path.join(train_dir, img_name)\n",
        "                    if img_name in label_dict:\n",
        "                        train_images.append(img_path)\n",
        "                        train_labels.append(label_dict[img_name])\n",
        "\n",
        "            print(f\"Loaded {len(train_images)} training images with labels\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading labels file: {e}\")\n",
        "            raise\n",
        "    else:\n",
        "        print(\"No labels file provided! Please create train_labels.csv\")\n",
        "        raise FileNotFoundError(\"train_labels.csv is required\")\n",
        "\n",
        "    # Load test data\n",
        "    test_images = []\n",
        "    test_ids = []\n",
        "\n",
        "    print(\"Loading test data...\")\n",
        "    if os.path.exists(test_dir):\n",
        "        for img_name in os.listdir(test_dir):\n",
        "            if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                img_path = os.path.join(test_dir, img_name)\n",
        "                test_images.append(img_path)\n",
        "                test_ids.append(img_name)\n",
        "\n",
        "        print(f\"Loaded {len(test_images)} test images\")\n",
        "\n",
        "    return train_images, train_labels, test_images, test_ids\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:14:06.978766Z",
          "iopub.execute_input": "2025-09-27T15:14:06.979465Z",
          "iopub.status.idle": "2025-09-27T15:14:06.985723Z",
          "shell.execute_reply.started": "2025-09-27T15:14:06.979441Z",
          "shell.execute_reply": "2025-09-27T15:14:06.985032Z"
        },
        "id": "U5LXWJcAsKLh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(model, dataloader, device):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(dataloader):\n",
        "                if len(batch) == 2:\n",
        "                    images, batch_labels = batch\n",
        "                    batch_labels = batch_labels.to(device)\n",
        "                    labels.extend(batch_labels.cpu().numpy())\n",
        "                else:\n",
        "                    images = batch\n",
        "\n",
        "                images = images.to(device)\n",
        "                _, batch_features = model(images)\n",
        "                features.extend(batch_features.cpu().numpy())\n",
        "\n",
        "                # Periodic cleanup\n",
        "                if batch_idx % 10 == 0:\n",
        "                    cleanup_memory()\n",
        "\n",
        "        return np.array(features), np.array(labels) if labels else None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Feature extraction failed: {e}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:14:08.83833Z",
          "iopub.execute_input": "2025-09-27T15:14:08.838899Z",
          "iopub.status.idle": "2025-09-27T15:14:08.844606Z",
          "shell.execute_reply.started": "2025-09-27T15:14:08.838875Z",
          "shell.execute_reply": "2025-09-27T15:14:08.843772Z"
        },
        "id": "675CNCRQsKLh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class AgriculturalClassifier:\n",
        "    \"\"\"Main classifier class with robustness features\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.cnn_model = None\n",
        "        self.xgb_model = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.class_names = None\n",
        "\n",
        "    def train_cnn(self, train_images, train_labels, val_images=None, val_labels=None, fold=0):\n",
        "      \"\"\"Train CNN model with robustness features and per-epoch logging\"\"\"\n",
        "      print(f\"Starting robust CNN training for fold {fold}\")\n",
        "\n",
        "      # Encode labels\n",
        "      encoded_labels = self.label_encoder.fit_transform(train_labels)\n",
        "      self.class_names = self.label_encoder.classes_\n",
        "      print(f\"Found {len(self.class_names)} classes: {self.class_names}\")\n",
        "\n",
        "      # Assign training and validation data based on whether validation data was provided\n",
        "      if val_images is None or val_labels is None:\n",
        "          print(\"Using StratifiedKFold for splitting data\")\n",
        "          from sklearn.model_selection import StratifiedKFold\n",
        "          skf = StratifiedKFold(n_splits=Config.N_SPLITS, shuffle=True, random_state=Config.SEED)\n",
        "          for fold_idx, (train_idx, val_idx) in enumerate(skf.split(train_images, encoded_labels)):\n",
        "              if fold_idx == fold:\n",
        "                  train_subset_imgs = [train_images[i] for i in train_idx]\n",
        "                  train_subset_labels = encoded_labels[train_idx]\n",
        "                  val_subset_imgs = [train_images[i] for i in val_idx]\n",
        "                  val_subset_labels = encoded_labels[val_idx]\n",
        "                  break\n",
        "          train_imgs_for_training = train_subset_imgs\n",
        "          train_labels_for_training = train_subset_labels\n",
        "          val_imgs_for_training = val_subset_imgs\n",
        "          val_labels_for_training = val_subset_labels\n",
        "\n",
        "      else:\n",
        "          print(\"Using provided validation data\")\n",
        "          train_imgs_for_training = train_images\n",
        "          train_labels_for_training = encoded_labels # Use encoded labels for training\n",
        "          val_imgs_for_training = val_images\n",
        "          val_labels_for_training = self.label_encoder.transform(val_labels) # Encode provided validation labels\n",
        "\n",
        "\n",
        "      # Create datasets\n",
        "      try:\n",
        "          train_dataset = AgriculturalDataset(\n",
        "              train_imgs_for_training, train_labels_for_training, get_transforms('train')\n",
        "          )\n",
        "          train_loader = DataLoader(\n",
        "              train_dataset, batch_size=Config.BATCH_SIZE,\n",
        "              shuffle=True, num_workers=0, pin_memory=False\n",
        "          )\n",
        "\n",
        "          val_dataset, val_loader = None, None\n",
        "          if val_imgs_for_training is not None:\n",
        "              val_dataset = AgriculturalDataset(\n",
        "                  val_imgs_for_training, val_labels_for_training, get_transforms('val')\n",
        "              )\n",
        "              val_loader = DataLoader(\n",
        "                  val_dataset, batch_size=Config.BATCH_SIZE,\n",
        "                  shuffle=False, num_workers=0, pin_memory=False\n",
        "              )\n",
        "      except Exception as e:\n",
        "          print(f\"Failed to create data loaders: {e}\")\n",
        "          raise\n",
        "\n",
        "      # Initialize model\n",
        "      self.cnn_model = ResNetClassifier(len(self.class_names)).to(device)\n",
        "      # In train_cnn method, replace the criterion with:\n",
        "\n",
        "    # Calculate class weights\n",
        "      class_weights = compute_class_weight(\n",
        "          'balanced',\n",
        "          classes=np.unique(encoded_labels),\n",
        "          y=encoded_labels\n",
        "      )\n",
        "      class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "    # Use weighted CrossEntropyLoss\n",
        "      # Calculate class weights for focal loss\n",
        "      # Calculate class weights for focal loss\n",
        "      import sklearn.utils.class_weight\n",
        "      unique_classes = np.unique(train_labels_for_training)\n",
        "      class_weights_array = sklearn.utils.class_weight.compute_class_weight(\n",
        "          'balanced',\n",
        "          classes=unique_classes,\n",
        "          y=train_labels_for_training\n",
        "      )\n",
        "      class_weights = torch.FloatTensor(class_weights_array).to(device)\n",
        "\n",
        "    # Use Focal Loss with class weights\n",
        "      criterion = FocalLoss(alpha=1, gamma=2, weight=class_weights)\n",
        "      optimizer = optim.AdamW(\n",
        "          self.cnn_model.parameters(),\n",
        "          lr=Config.LEARNING_RATE,\n",
        "          weight_decay=1e-4\n",
        "      )\n",
        "\n",
        "      scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "          optimizer,\n",
        "          max_lr=Config.LEARNING_RATE,\n",
        "          steps_per_epoch=len(train_loader),\n",
        "          epochs=Config.EPOCHS,\n",
        "          pct_start=0.3,\n",
        "          div_factor=25,\n",
        "          final_div_factor=10000\n",
        "      )\n",
        "\n",
        "      # Check for existing checkpoint\n",
        "      checkpoint_path = os.path.join(Config.CHECKPOINT_DIR, f'fold_{fold}_latest.pth')\n",
        "      start_epoch, start_batch, best_val_acc = 0, 0, 0.0\n",
        "\n",
        "      if Config.RESUME_FROM_CHECKPOINT:\n",
        "          checkpoint_info = load_checkpoint(checkpoint_path, self.cnn_model, optimizer, scheduler)\n",
        "          if checkpoint_info:\n",
        "              start_epoch = checkpoint_info['epoch']\n",
        "              start_batch = checkpoint_info.get('batch_idx', 0)\n",
        "              print(f\"Resuming from epoch {start_epoch}, batch {start_batch}\")\n",
        "\n",
        "      train_losses, val_accuracies = [], []\n",
        "      no_improvement_count = 0\n",
        "\n",
        "      try:\n",
        "          for epoch in range(start_epoch, Config.EPOCHS):\n",
        "              print(f\"Starting epoch {epoch+1}/{Config.EPOCHS}\")\n",
        "              monitor_memory()\n",
        "\n",
        "              # Training phase\n",
        "              self.cnn_model.train()\n",
        "              running_loss, correct, total = 0.0, 0, 0\n",
        "              epoch_start_time = time.time()\n",
        "\n",
        "              batch_start = start_batch if epoch == start_epoch else 0\n",
        "\n",
        "              for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "                  if batch_idx < batch_start:\n",
        "                      continue\n",
        "\n",
        "                  images, labels = images.to(device), labels.to(device)\n",
        "                  optimizer.zero_grad()\n",
        "\n",
        "                # Apply mixup 40% of the time\n",
        "                  if np.random.rand() < 0.4:\n",
        "                      images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=0.3)\n",
        "                      outputs, _ = self.cnn_model(images)\n",
        "                      loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
        "                    # For accuracy calculation, use original labels\n",
        "                      _, predicted = outputs.max(1)\n",
        "                      total += labels.size(0)\n",
        "                      correct += (lam * predicted.eq(labels_a).sum().item() +\n",
        "                                (1-lam) * predicted.eq(labels_b).sum().item())\n",
        "                  else:\n",
        "                      outputs, _ = self.cnn_model(images)\n",
        "                      loss = criterion(outputs, labels)\n",
        "                      _, predicted = outputs.max(1)\n",
        "                      total += labels.size(0)\n",
        "                      correct += predicted.eq(labels).sum().item()\n",
        "                  loss.backward()\n",
        "                  torch.nn.utils.clip_grad_norm_(self.cnn_model.parameters(), max_norm=1.0)\n",
        "                  optimizer.step()\n",
        "\n",
        "                  running_loss += loss.item()\n",
        "                  _, predicted = outputs.max(1)\n",
        "                  total += labels.size(0)\n",
        "                  correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "              epoch_loss = running_loss / len(train_loader)\n",
        "              train_acc = 100. * correct / total\n",
        "              train_losses.append(epoch_loss)\n",
        "\n",
        "              # Validation phase\n",
        "              val_acc = 0.0\n",
        "              if val_loader is not None:\n",
        "                  val_acc = self._validate(val_loader) * 100\n",
        "                  val_accuracies.append(val_acc)\n",
        "\n",
        "                  if val_acc > best_val_acc:\n",
        "                      best_val_acc, no_improvement_count = val_acc, 0\n",
        "                      best_model_path = os.path.join(Config.CHECKPOINT_DIR, f'best_model_fold_{fold}.pth')\n",
        "                      torch.save(self.cnn_model.state_dict(), best_model_path)\n",
        "                      print(f\"New best validation accuracy: {val_acc:.2f}%\")\n",
        "                  else:\n",
        "                      no_improvement_count += 1\n",
        "                      if no_improvement_count >= Config.PATIENCE:\n",
        "                          print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                          break\n",
        "\n",
        "              # Log epoch summary\n",
        "              epoch_time = time.time() - epoch_start_time\n",
        "              print(\n",
        "                  f'Fold {fold}, Epoch [{epoch+1}/{Config.EPOCHS}] '\n",
        "                  f'Loss: {epoch_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, '\n",
        "                  f'Time: {epoch_time:.1f}s'\n",
        "              )\n",
        "\n",
        "              # Save checkpoint\n",
        "              save_checkpoint(\n",
        "                  self.cnn_model, optimizer, scheduler,\n",
        "                  epoch+1, fold, 0, epoch_loss, checkpoint_path\n",
        "              )\n",
        "              scheduler.step()\n",
        "              cleanup_memory()\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Training failed: {e}\")\n",
        "          emergency_path = os.path.join(Config.CHECKPOINT_DIR, f'emergency_fold_{fold}.pth')\n",
        "          try:\n",
        "              save_checkpoint(\n",
        "                  self.cnn_model, optimizer, scheduler,\n",
        "                  epoch, fold, 0, epoch_loss if 'epoch_loss' in locals() else 0.0,\n",
        "                  emergency_path\n",
        "              )\n",
        "          except:\n",
        "              pass\n",
        "          raise\n",
        "\n",
        "      return train_losses, val_accuracies\n",
        "\n",
        "\n",
        "    def _validate(self, val_loader):\n",
        "        \"\"\"Validate model with error handling\"\"\"\n",
        "        self.cnn_model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "                    try:\n",
        "                        images, labels = images.to(device), labels.to(device)\n",
        "                        outputs, _ = self.cnn_model(images)\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        total += labels.size(0)\n",
        "                        correct += (predicted == labels).sum().item()\n",
        "\n",
        "                        # Memory cleanup every few batches\n",
        "                        if batch_idx % 10 == 0:\n",
        "                            cleanup_memory()\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Validation batch {batch_idx} failed: {e}\")\n",
        "                        continue\n",
        "\n",
        "            accuracy = correct / total if total > 0 else 0.0\n",
        "            return accuracy\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Validation failed: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    def train_xgboost(self, features, labels):\n",
        "        \"\"\"Train XGBoost model on CNN features\"\"\"\n",
        "        print(\"Training XGBoost model...\")\n",
        "\n",
        "        try:\n",
        "            self.xgb_model = xgb.XGBClassifier(\n",
        "                n_estimators=200,\n",
        "                max_depth=6,\n",
        "                learning_rate=0.1,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                random_state=Config.SEED,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "\n",
        "            self.xgb_model.fit(features, labels)\n",
        "            print(\"XGBoost training completed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"XGBoost training failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def predict(self, test_images, tta_transforms=None):\n",
        "        \"\"\"Make predictions on test data using TTA with probability averaging.\"\"\"\n",
        "        print(\"Making predictions with TTA...\")\n",
        "\n",
        "        if tta_transforms is None:\n",
        "            # Enhanced TTA with 6 augmentations\n",
        "            tta_transforms = [\n",
        "                get_transforms('val'),  # original\n",
        "                A.Compose([\n",
        "                    A.Resize(Config.IMG_SIZE, Config.IMG_SIZE),\n",
        "                    A.HorizontalFlip(p=1.0),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ]),\n",
        "                A.Compose([\n",
        "                    A.Resize(Config.IMG_SIZE, Config.IMG_SIZE),\n",
        "                    A.VerticalFlip(p=1.0),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ]),\n",
        "                A.Compose([\n",
        "                    A.Resize(Config.IMG_SIZE, Config.IMG_SIZE),\n",
        "                    A.Transpose(p=1.0),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ]),\n",
        "                A.Compose([\n",
        "                    A.Resize(Config.IMG_SIZE, Config.IMG_SIZE),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=1.0),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ]),\n",
        "                A.Compose([\n",
        "                    A.Resize(Config.IMG_SIZE, Config.IMG_SIZE),\n",
        "                    A.HorizontalFlip(p=1.0),\n",
        "                    A.VerticalFlip(p=1.0),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            ]\n",
        "\n",
        "        try:\n",
        "            self.cnn_model.eval()\n",
        "            final_predictions = []\n",
        "            all_probs = []\n",
        "\n",
        "            for idx, img_path in enumerate(test_images):\n",
        "                tta_probs = []\n",
        "\n",
        "                # Load the image first\n",
        "                try:\n",
        "                    if not os.path.exists(img_path):\n",
        "                        print(f\"Image not found: {img_path}\")\n",
        "                        continue\n",
        "\n",
        "                    image = cv2.imread(img_path)\n",
        "                    if image is None:\n",
        "                        print(f\"Failed to load image: {img_path}\")\n",
        "                        continue\n",
        "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image {img_path}: {e}\")\n",
        "                    continue\n",
        "\n",
        "                # Apply each TTA transform\n",
        "                for tform in tta_transforms:\n",
        "                    augmented = tform(image=image)  # Use named argument\n",
        "                    img_tensor = augmented['image'].unsqueeze(0).to(device)  # Add batch dim  # Add batch dim\n",
        "                    with torch.no_grad():\n",
        "                        outputs, features = self.cnn_model(img_tensor)\n",
        "                        probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "                        tta_probs.append(probs[0])\n",
        "\n",
        "                # Average probabilities across TTA\n",
        "                avg_probs = np.mean(tta_probs, axis=0)\n",
        "\n",
        "                # XGBoost predictions if model exists\n",
        "                if self.xgb_model is not None:\n",
        "                    # Extract features for XGBoost\n",
        "                    with torch.no_grad():\n",
        "                        _, features = self.cnn_model(augmented['image'].unsqueeze(0).to(device))\n",
        "                        xgb_prob = self.xgb_model.predict_proba(features.cpu().numpy())\n",
        "                        # Weighted combination: CNN 70%, XGBoost 30%\n",
        "                        combined_probs = 0.7 * avg_probs + 0.3 * xgb_prob[0]\n",
        "                else:\n",
        "                    combined_probs = avg_probs\n",
        "\n",
        "                all_probs.append(combined_probs)\n",
        "                final_predictions.append(np.argmax(combined_probs))\n",
        "\n",
        "                if idx % 50 == 0:\n",
        "                    print(f\"Processed {idx+1}/{len(test_images)} images\")\n",
        "\n",
        "            # Convert back to class names\n",
        "            predicted_classes = self.label_encoder.inverse_transform(final_predictions)\n",
        "            return predicted_classes, np.array(all_probs)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Prediction failed: {e}\")\n",
        "            raise\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:18:48.777577Z",
          "iopub.execute_input": "2025-09-27T15:18:48.777895Z",
          "iopub.status.idle": "2025-09-27T15:18:48.808409Z",
          "shell.execute_reply.started": "2025-09-27T15:18:48.777875Z",
          "shell.execute_reply": "2025-09-27T15:18:48.807692Z"
        },
        "id": "lSljVLPgsKLh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_cross_validation(train_images, train_labels):\n",
        "    print(\"Starting robust cross-validation...\")\n",
        "\n",
        "    # Save cross-validation state\n",
        "    cv_state_file = os.path.join(Config.CHECKPOINT_DIR, 'cv_state.json')\n",
        "\n",
        "    # Load existing CV state if available\n",
        "    cv_scores = []\n",
        "    completed_folds = []\n",
        "\n",
        "    if os.path.exists(cv_state_file) and Config.RESUME_FROM_CHECKPOINT:\n",
        "        try:\n",
        "            with open(cv_state_file, 'r') as f:\n",
        "                cv_state = json.load(f)\n",
        "                cv_scores = cv_state.get('scores', [])\n",
        "                completed_folds = cv_state.get('completed_folds', [])\n",
        "            print(f\"Resuming CV from fold {len(completed_folds) + 1}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load CV state: {e}\")\n",
        "\n",
        "    classifier = AgriculturalClassifier()\n",
        "    encoded_labels = classifier.label_encoder.fit_transform(train_labels)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=Config.NUM_FOLDS, shuffle=True, random_state=Config.SEED)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_images, encoded_labels)):\n",
        "        if fold in completed_folds:\n",
        "            print(f\"Fold {fold + 1} already completed, skipping\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Starting Fold {fold + 1}/{Config.NUM_FOLDS}\")\n",
        "\n",
        "        try:\n",
        "            # Split data\n",
        "            fold_train_images = [train_images[i] for i in train_idx]\n",
        "            fold_train_labels = [train_labels[i] for i in train_idx]\n",
        "            fold_val_images = [train_images[i] for i in val_idx]\n",
        "            fold_val_labels = [train_labels[i] for i in val_idx]\n",
        "\n",
        "            # Train fold model\n",
        "            fold_classifier = AgriculturalClassifier()\n",
        "            fold_classifier.train_cnn(\n",
        "                fold_train_images, fold_train_labels,\n",
        "                fold_val_images, fold_val_labels, fold=fold\n",
        "            )\n",
        "\n",
        "            # Evaluate\n",
        "            val_dataset = AgriculturalDataset(\n",
        "                fold_val_images,\n",
        "                fold_classifier.label_encoder.transform(fold_val_labels),\n",
        "                get_transforms('val')\n",
        "            )\n",
        "            val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE,\n",
        "                                  shuffle=False, num_workers=0)\n",
        "\n",
        "            val_acc = fold_classifier._validate(val_loader)\n",
        "            cv_scores.append(val_acc)\n",
        "            completed_folds.append(fold)\n",
        "\n",
        "            print(f\"Fold {fold + 1} completed - Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "            # Save CV progress\n",
        "            cv_state = {\n",
        "                'scores': cv_scores,\n",
        "                'completed_folds': completed_folds,\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            }\n",
        "            with open(cv_state_file, 'w') as f:\n",
        "                json.dump(cv_state, f)\n",
        "\n",
        "            # Cleanup before next fold\n",
        "            del fold_classifier\n",
        "            cleanup_memory()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Fold {fold + 1} failed: {e}\")\n",
        "            print(\"You can restart the script to resume from the next fold\")\n",
        "            break\n",
        "\n",
        "    if cv_scores:\n",
        "        print(f\"Cross-validation scores: {cv_scores}\")\n",
        "        print(f\"Mean CV Score: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores) * 2:.4f})\")\n",
        "    else:\n",
        "        print(\"No CV scores available\")\n",
        "\n",
        "    return cv_scores"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:14:49.198547Z",
          "iopub.execute_input": "2025-09-27T15:14:49.199224Z",
          "iopub.status.idle": "2025-09-27T15:14:49.20844Z",
          "shell.execute_reply.started": "2025-09-27T15:14:49.199203Z",
          "shell.execute_reply": "2025-09-27T15:14:49.207687Z"
        },
        "id": "zXoxpwaxsKLi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_data_distribution(train_labels):\n",
        "    print(\"Analyzing data distribution...\")\n",
        "\n",
        "    # Count distribution\n",
        "    class_counts = Counter(train_labels)\n",
        "    print(\"\\nClass distribution:\")\n",
        "    for class_name, count in sorted(class_counts.items()):\n",
        "        print(f\"{class_name}: {count}\")\n",
        "\n",
        "    # Plot distribution\n",
        "    try:\n",
        "        plt.figure(figsize=(15, 8))\n",
        "        classes = list(class_counts.keys())\n",
        "        counts = list(class_counts.values())\n",
        "\n",
        "        plt.bar(classes, counts)\n",
        "        plt.title('Class Distribution in Training Data')\n",
        "        plt.xlabel('Classes')\n",
        "        plt.ylabel('Number of Images')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save plot\n",
        "        plot_path = os.path.join(Config.CHECKPOINT_DIR, 'class_distribution.png')\n",
        "        plt.savefig(plot_path)\n",
        "        plt.show()\n",
        "        print(f\"Class distribution plot saved to {plot_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not create distribution plot: {e}\")\n",
        "\n",
        "    return class_counts"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:14:51.558153Z",
          "iopub.execute_input": "2025-09-27T15:14:51.558704Z",
          "iopub.status.idle": "2025-09-27T15:14:51.564079Z",
          "shell.execute_reply.started": "2025-09-27T15:14:51.558679Z",
          "shell.execute_reply": "2025-09-27T15:14:51.563471Z"
        },
        "id": "dQvG5sxhsKLi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission(test_ids, predictions, filename='submission.csv'):\n",
        "    try:\n",
        "        submission_df = pd.DataFrame({\n",
        "            'ID': test_ids,\n",
        "            'TARGET': predictions\n",
        "        })\n",
        "        submission_df.to_csv(filename, index=False)\n",
        "        print(f\"Submission file saved as {filename}\")\n",
        "        return submission_df\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create submission: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:14:53.738085Z",
          "iopub.execute_input": "2025-09-27T15:14:53.738576Z",
          "iopub.status.idle": "2025-09-27T15:14:53.742576Z",
          "shell.execute_reply.started": "2025-09-27T15:14:53.738553Z",
          "shell.execute_reply": "2025-09-27T15:14:53.741943Z"
        },
        "id": "vzjz3V-SsKLi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_labels_file():\n",
        "    \"\"\"This function is not needed for Kaggle competitions - they provide train.csv\"\"\"\n",
        "\n",
        "    train_dir = \"/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train/train\"\n",
        "    train_csv_path = \"/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train.csv\"\n",
        "\n",
        "    # First check if the actual train.csv already exists\n",
        "    if os.path.exists(train_csv_path):\n",
        "        print(\"train.csv already exists! Using the actual labels from the dataset.\")\n",
        "        try:\n",
        "            train_df = pd.read_csv(train_csv_path)\n",
        "            print(f\"Found {len(train_df)} labeled images\")\n",
        "            print(f\"Classes in dataset: {sorted(train_df['TARGET'].unique())}\")\n",
        "            print(f\"Number of classes: {train_df['TARGET'].nunique()}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading existing train.csv: {e}\")\n",
        "            return False\n",
        "\n",
        "    # If for some reason train.csv doesn't exist, create a dynamic version\n",
        "    print(\"train.csv not found. This is unusual for a Kaggle competition.\")\n",
        "    print(\"Creating a sample version, but you should use the actual train.csv from the dataset.\")\n",
        "\n",
        "    if not os.path.exists(train_dir):\n",
        "        print(\"Train directory not found!\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Get all image files\n",
        "        image_files = []\n",
        "        for img_name in os.listdir(train_dir):\n",
        "            if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_files.append(img_name)\n",
        "\n",
        "        if not image_files:\n",
        "            print(\"No image files found in train directory!\")\n",
        "            return False\n",
        "\n",
        "        # Try to infer classes from filename patterns instead of hardcoding\n",
        "        print(\"Attempting to infer classes from filename patterns...\")\n",
        "\n",
        "        # Method 1: Look for common prefixes/patterns in filenames\n",
        "        prefixes = set()\n",
        "        for img_name in image_files[:100]:  # Sample first 100 files\n",
        "            base_name = os.path.splitext(img_name)[0]\n",
        "\n",
        "            # Try different pattern extraction methods\n",
        "            if '_' in base_name:\n",
        "                prefix = base_name.split('_')[0]\n",
        "                prefixes.add(prefix)\n",
        "            elif '-' in base_name:\n",
        "                prefix = base_name.split('-')[0]\n",
        "                prefixes.add(prefix)\n",
        "            else:\n",
        "                # Extract alphabetic prefix\n",
        "                import re\n",
        "                match = re.match(r'^([A-Za-z]+)', base_name)\n",
        "                if match:\n",
        "                    prefixes.add(match.group(1))\n",
        "\n",
        "        if len(prefixes) > 1 and len(prefixes) < 50:\n",
        "            sample_classes = sorted(list(prefixes))\n",
        "            print(f\"Inferred {len(sample_classes)} classes from filenames: {sample_classes}\")\n",
        "        else:\n",
        "            # Fallback: Generate generic class names based on estimated number\n",
        "            estimated_classes = max(3, min(20, len(image_files) // 100))  # Estimate based on dataset size\n",
        "            sample_classes = [f\"CLASS_{i+1}\" for i in range(estimated_classes)]\n",
        "            print(f\"Could not infer classes from filenames. Using {estimated_classes} generic classes.\")\n",
        "\n",
        "        # Assign labels using different strategies\n",
        "        labels_data = []\n",
        "\n",
        "        if len(prefixes) > 1:\n",
        "            # Use filename pattern matching\n",
        "            for img_name in sorted(image_files):\n",
        "                base_name = os.path.splitext(img_name)[0]\n",
        "\n",
        "                # Find matching prefix\n",
        "                assigned_class = None\n",
        "                for prefix in sample_classes:\n",
        "                    if base_name.startswith(prefix) or prefix in base_name:\n",
        "                        assigned_class = prefix\n",
        "                        break\n",
        "\n",
        "                if not assigned_class:\n",
        "                    # Fallback to round-robin\n",
        "                    assigned_class = sample_classes[len(labels_data) % len(sample_classes)]\n",
        "\n",
        "                labels_data.append({'ID': img_name, 'TARGET': assigned_class})\n",
        "        else:\n",
        "            # Round-robin assignment\n",
        "            for img_name in sorted(image_files):\n",
        "                label_idx = len(labels_data) % len(sample_classes)\n",
        "                sample_label = sample_classes[label_idx]\n",
        "                labels_data.append({'ID': img_name, 'TARGET': sample_label})\n",
        "\n",
        "        # Save to working directory (not the input directory which is read-only)\n",
        "        output_path = '/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train.csv'  # Save to current working directory\n",
        "        labels_df = pd.DataFrame(labels_data)\n",
        "        labels_df.to_csv(output_path, index=False)\n",
        "\n",
        "        # Show class distribution\n",
        "        class_counts = labels_df['TARGET'].value_counts()\n",
        "        print(f\"Created train.csv with {len(labels_data)} entries\")\n",
        "        print(f\"Number of classes: {len(sample_classes)}\")\n",
        "        print(\"Class distribution:\")\n",
        "        for class_name, count in class_counts.items():\n",
        "            print(f\"  {class_name}: {count}\")\n",
        "\n",
        "        print(\"WARNING: This is a SAMPLE file created because train.csv was missing!\")\n",
        "        print(\"For the actual competition, use the provided train.csv from the dataset!\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create sample labels file: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:14:55.158716Z",
          "iopub.execute_input": "2025-09-27T15:14:55.158995Z",
          "iopub.status.idle": "2025-09-27T15:14:55.170433Z",
          "shell.execute_reply.started": "2025-09-27T15:14:55.158975Z",
          "shell.execute_reply": "2025-09-27T15:14:55.169762Z"
        },
        "id": "TKbUU76msKLi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def resume_training_from_checkpoint():\n",
        "    checkpoint_dir = Config.CHECKPOINT_DIR\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        print(\"No checkpoint directory found\")\n",
        "        return False\n",
        "\n",
        "    # List available checkpoints\n",
        "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
        "\n",
        "    if not checkpoints:\n",
        "        print(\"No checkpoints found\")\n",
        "        return False\n",
        "\n",
        "    print(\"\\nAvailable checkpoints:\")\n",
        "    for i, ckpt in enumerate(checkpoints):\n",
        "        print(f\"{i}: {ckpt}\")\n",
        "\n",
        "    try:\n",
        "        choice = input(\"Enter checkpoint number to resume from (or 'latest'): \").strip()\n",
        "\n",
        "        if choice.lower() == 'latest':\n",
        "            # Find latest checkpoint\n",
        "            checkpoint_files = [(f, os.path.getmtime(os.path.join(checkpoint_dir, f)))\n",
        "                              for f in checkpoints]\n",
        "            checkpoint_files.sort(key=lambda x: x[1], reverse=True)\n",
        "            chosen_checkpoint = checkpoint_files[0][0]\n",
        "        else:\n",
        "            chosen_checkpoint = checkpoints[int(choice)]\n",
        "\n",
        "        print(f\"Will resume from: {chosen_checkpoint}\")\n",
        "        Config.RESUME_FROM_CHECKPOINT = True\n",
        "\n",
        "        return True\n",
        "\n",
        "    except (ValueError, IndexError):\n",
        "        print(\"Invalid choice\")\n",
        "        return False"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:14:58.428418Z",
          "iopub.execute_input": "2025-09-27T15:14:58.428729Z",
          "iopub.status.idle": "2025-09-27T15:14:58.4358Z",
          "shell.execute_reply.started": "2025-09-27T15:14:58.428707Z",
          "shell.execute_reply": "2025-09-27T15:14:58.434817Z"
        },
        "id": "Jek6OvmwsKLi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_setup():\n",
        "    required_dirs = [\"/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train/train\", \"/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/test/test\"]\n",
        "    required_files = [\"/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train.csv\"]\n",
        "\n",
        "    missing_dirs = [d for d in required_dirs if not os.path.exists(d)]\n",
        "    missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "\n",
        "    if missing_dirs or missing_files:\n",
        "        print(\"Setup validation failed!\")\n",
        "\n",
        "        if missing_dirs:\n",
        "            print(f\"Missing directories: {missing_dirs}\")\n",
        "\n",
        "        if missing_files:\n",
        "            print(f\"Missing files: {missing_files}\")\n",
        "            if \"train_labels.csv\" in missing_files:\n",
        "                print(\"You can create a sample train_labels.csv file using create_sample_labels_file()\")\n",
        "\n",
        "        return False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:15:00.298104Z",
          "iopub.execute_input": "2025-09-27T15:15:00.298351Z",
          "iopub.status.idle": "2025-09-27T15:15:00.303394Z",
          "shell.execute_reply.started": "2025-09-27T15:15:00.298327Z",
          "shell.execute_reply": "2025-09-27T15:15:00.302655Z"
        },
        "id": "ms8iyL36sKLi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def monitor_memory():\n",
        "    \"\"\"Monitor memory usage\"\"\"\n",
        "    try:\n",
        "        return psutil.virtual_memory().percent\n",
        "    except:\n",
        "        return 50.0  # Default fallback\n",
        "\n",
        "def load_checkpoint(checkpoint_path, model, optimizer, scheduler):\n",
        "    \"\"\"Load checkpoint if exists\"\"\"\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        try:\n",
        "            checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            if scheduler and checkpoint.get('scheduler_state_dict'):\n",
        "                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "            return checkpoint\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load checkpoint: {e}\")\n",
        "            return None\n",
        "    return None"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:15:01.617963Z",
          "iopub.execute_input": "2025-09-27T15:15:01.618504Z",
          "iopub.status.idle": "2025-09-27T15:15:01.62348Z",
          "shell.execute_reply.started": "2025-09-27T15:15:01.618479Z",
          "shell.execute_reply": "2025-09-27T15:15:01.622721Z"
        },
        "id": "Pt4cAK-wsKLi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_train_and_predict():\n",
        "    print(\"Agricultural Multi-Class Classifier - Maximum Performance Training\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    try:\n",
        "        TRAIN_DIR = \"/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train/train\"\n",
        "        TEST_DIR = \"/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/test/test\"\n",
        "        LABELS_FILE = \"/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train.csv\"\n",
        "\n",
        "        if not os.path.exists(TRAIN_DIR) or not os.path.exists(LABELS_FILE):\n",
        "            print(f\"Required files not found!\")\n",
        "            return None, None\n",
        "\n",
        "        # Load data\n",
        "        train_images, train_labels, test_images, test_ids = load_data(\n",
        "            TRAIN_DIR, TEST_DIR, LABELS_FILE\n",
        "        )\n",
        "\n",
        "        print(f\"Training images: {len(train_images)}\")\n",
        "        print(f\"Test images: {len(test_images)}\")\n",
        "        print(f\"Number of classes: {len(set(train_labels))}\")\n",
        "\n",
        "        if len(train_images) == 0:\n",
        "            return None, None\n",
        "\n",
        "        # Train all folds\n",
        "        fold_classifiers = []\n",
        "\n",
        "        for fold in range(Config.N_SPLITS):\n",
        "            print(f\"=== Training fold {fold + 1}/{Config.N_SPLITS} ===\")\n",
        "            classifier = AgriculturalClassifier()\n",
        "            train_losses, val_accuracies = classifier.train_cnn(train_images, train_labels, fold=fold)\n",
        "\n",
        "            # Load best model\n",
        "            best_model_path = os.path.join(Config.CHECKPOINT_DIR, f'best_model_fold_{fold}.pth')\n",
        "            if os.path.exists(best_model_path):\n",
        "                classifier.cnn_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "\n",
        "            fold_classifiers.append(classifier)\n",
        "            cleanup_memory()\n",
        "\n",
        "        # Extract features for XGBoost\n",
        "        print(\"Extracting features for XGBoost training...\")\n",
        "        all_features = []\n",
        "\n",
        "        for fold_idx, classifier in enumerate(fold_classifiers):\n",
        "            print(f\"Extracting features from fold {fold_idx + 1}\")\n",
        "\n",
        "            feature_dataset = AgriculturalDataset(train_images, None, get_transforms('val'))\n",
        "            feature_loader = DataLoader(feature_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "\n",
        "            features, _ = extract_features(classifier.cnn_model, feature_loader, device)\n",
        "            all_features.append(features)\n",
        "            cleanup_memory()\n",
        "\n",
        "        # Train XGBoost on ensemble features\n",
        "        print(\"Training XGBoost ensemble...\")\n",
        "        ensemble_features = np.mean(all_features, axis=0)\n",
        "        encoded_labels = fold_classifiers[0].label_encoder.transform(train_labels)\n",
        "\n",
        "        # Enhanced XGBoost\n",
        "        xgb_model = xgb.XGBClassifier(\n",
        "            n_estimators=300,\n",
        "            max_depth=8,\n",
        "            learning_rate=0.08,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            reg_alpha=0.1,\n",
        "            reg_lambda=0.1,\n",
        "            random_state=Config.SEED,\n",
        "            n_jobs=-1,\n",
        "            eval_metric='mlogloss'\n",
        "        )\n",
        "        xgb_model.fit(ensemble_features, encoded_labels)\n",
        "\n",
        "        # Assign XGBoost to all classifiers\n",
        "        for classifier in fold_classifiers:\n",
        "            classifier.xgb_model = xgb_model\n",
        "\n",
        "        print(\"Making ensemble predictions with CNN + XGBoost...\")\n",
        "        all_fold_predictions = []\n",
        "        all_fold_probs = []\n",
        "\n",
        "        # Get fold weights based on validation performance\n",
        "        fold_weights = []\n",
        "        for fold_idx in range(Config.N_SPLITS):\n",
        "            acc_file = os.path.join(Config.CHECKPOINT_DIR, f'best_acc_fold_{fold_idx}.txt')\n",
        "            if os.path.exists(acc_file):\n",
        "                with open(acc_file, 'r') as f:\n",
        "                    weight = float(f.read().strip())\n",
        "            else:\n",
        "                weight = 0.9\n",
        "            fold_weights.append(weight)\n",
        "\n",
        "        fold_weights = np.array(fold_weights)\n",
        "        fold_weights = fold_weights / fold_weights.sum()\n",
        "\n",
        "        for fold_idx, classifier in enumerate(fold_classifiers):\n",
        "            print(f\"Getting predictions from fold {fold_idx + 1} (weight: {fold_weights[fold_idx]:.3f})\")\n",
        "            fold_predictions, fold_probs = classifier.predict(test_images)\n",
        "            all_fold_predictions.append(fold_predictions)\n",
        "            all_fold_probs.append(fold_probs)\n",
        "\n",
        "        # Weighted ensemble\n",
        "        weighted_probs = np.average(all_fold_probs, axis=0, weights=fold_weights)\n",
        "        ensemble_predictions = fold_classifiers[0].label_encoder.inverse_transform(\n",
        "            np.argmax(weighted_probs, axis=1)\n",
        "        )\n",
        "\n",
        "        submission_df = create_submission(test_ids, ensemble_predictions)\n",
        "\n",
        "        return fold_classifiers[0], submission_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Training failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:15:04.53881Z",
          "iopub.execute_input": "2025-09-27T15:15:04.539382Z",
          "iopub.status.idle": "2025-09-27T15:15:04.550674Z",
          "shell.execute_reply.started": "2025-09-27T15:15:04.539362Z",
          "shell.execute_reply": "2025-09-27T15:15:04.549893Z"
        },
        "id": "xG0hbyIrsKLi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function with setup and options\"\"\"\n",
        "\n",
        "    print(\"Enhanced Agricultural Classifier with Cross-Validation Training\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"Features:\")\n",
        "    print(\"- Automatic checkpointing every epoch and every 50 batches\")\n",
        "    print(\"- Memory monitoring and automatic cleanup\")\n",
        "    print(\"- Automatic batch size reduction on OOM errors\")\n",
        "    print(\"- Resume training from any checkpoint\")\n",
        "    print(\"- Early stopping to prevent overfitting\")\n",
        "    print(\"- Individual fold recovery in cross-validation\")\n",
        "    print(\"- Comprehensive logging to file and console\")\n",
        "    print(\"- Data validation and error handling\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Check directory structure\n",
        "    if not os.path.exists(\"/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train/train\"):\n",
        "        print(\"Train directory 'train/train' not found!\")\n",
        "        if os.path.exists(\"/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train/train\"):\n",
        "            print(\"Found 'train' directory. Please check the structure:\")\n",
        "            print(\"Expected: train/train/ (with image files)\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(\"/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/test/test\"):\n",
        "        print(\"Test directory 'test' not found!\")\n",
        "        print(\"Please create test directory with test images\")\n",
        "        return\n",
        "\n",
        "\n",
        "    print(\"DEBUG: Starting quick_train_and_predict()...\")\n",
        "\n",
        "    classifier, submission = quick_train_and_predict()\n",
        "\n",
        "    if classifier is not None and submission is not None:\n",
        "        print(\"Training pipeline completed successfully!\")\n",
        "        print(f\"Submission file created: submission.csv\")\n",
        "        print(f\"All checkpoints saved in: {Config.CHECKPOINT_DIR}/\")\n",
        "        print(f\"Training logs available in the log file\")\n",
        "\n",
        "        # Display submission summary\n",
        "        print(f\"Submission Summary:\")\n",
        "        print(f\"Total predictions: {len(submission)}\")\n",
        "        print(f\"Unique classes predicted: {submission['TARGET'].nunique()}\")\n",
        "        print(f\"Most predicted class: {submission['TARGET'].mode().iloc[0]}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Training pipeline failed or was interrupted\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:15:07.26169Z",
          "iopub.execute_input": "2025-09-27T15:15:07.261942Z",
          "iopub.status.idle": "2025-09-27T15:15:07.268306Z",
          "shell.execute_reply.started": "2025-09-27T15:15:07.261925Z",
          "shell.execute_reply": "2025-09-27T15:15:07.26757Z"
        },
        "id": "Pd9cdt9asKLi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T15:19:04.058057Z",
          "iopub.execute_input": "2025-09-27T15:19:04.05874Z",
          "iopub.status.idle": "2025-09-27T17:41:41.096235Z",
          "shell.execute_reply.started": "2025-09-27T15:19:04.058716Z",
          "shell.execute_reply": "2025-09-27T17:41:41.095423Z"
        },
        "id": "ZPPoTsG6sKLj",
        "outputId": "4893dad6-09a3-413a-a353-08cb51b54d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Enhanced Agricultural Classifier with Cross-Validation Training\n======================================================================\nFeatures:\n- Automatic checkpointing every epoch and every 50 batches\n- Memory monitoring and automatic cleanup\n- Automatic batch size reduction on OOM errors\n- Resume training from any checkpoint\n- Early stopping to prevent overfitting\n- Individual fold recovery in cross-validation\n- Comprehensive logging to file and console\n- Data validation and error handling\n======================================================================\nDEBUG: Starting quick_train_and_predict()...\nAgricultural Multi-Class Classifier - Maximum Performance Training\n======================================================================\nLoading training data...\nLoaded 6400 training images with labels\nLoading test data...\nLoaded 1600 test images\nTraining images: 6400\nTest images: 1600\nNumber of classes: 20\n=== Training fold 1/4 ===\nStarting robust CNN training for fold 0\nFound 20 classes: ['AK' 'ALA_IDRIS' 'ARBORIO' 'BASMATI' 'BD30' 'BD72' 'BD95' 'BINADHAN16'\n 'BINADHAN25' 'BINADHAN7' 'BR22' 'BRRI67' 'BUZGULU' 'DIMNIT' 'IPSALA'\n 'JASMINE' 'KARACADAG' 'KIRMIZI' 'NAZLI' 'SIIRT']\nUsing StratifiedKFold for splitting data\nStarting epoch 1/18\nNew best validation accuracy: 43.00%\nFold 0, Epoch [1/18] Loss: 3.1727, Train Acc: 9.80%, Val Acc: 43.00%, Time: 138.9s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 2/18\nNew best validation accuracy: 60.06%\nFold 0, Epoch [2/18] Loss: 2.3576, Train Acc: 20.16%, Val Acc: 60.06%, Time: 102.0s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 3/18\nNew best validation accuracy: 67.19%\nFold 0, Epoch [3/18] Loss: 1.8612, Train Acc: 31.39%, Val Acc: 67.19%, Time: 102.0s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 4/18\nNew best validation accuracy: 74.19%\nFold 0, Epoch [4/18] Loss: 1.6064, Train Acc: 37.35%, Val Acc: 74.19%, Time: 101.3s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 5/18\nNew best validation accuracy: 77.75%\nFold 0, Epoch [5/18] Loss: 1.4370, Train Acc: 42.86%, Val Acc: 77.75%, Time: 100.7s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 6/18\nNew best validation accuracy: 79.94%\nFold 0, Epoch [6/18] Loss: 1.3614, Train Acc: 45.90%, Val Acc: 79.94%, Time: 101.8s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 7/18\nNew best validation accuracy: 80.75%\nFold 0, Epoch [7/18] Loss: 1.2273, Train Acc: 49.12%, Val Acc: 80.75%, Time: 102.6s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 8/18\nNew best validation accuracy: 84.81%\nFold 0, Epoch [8/18] Loss: 1.1268, Train Acc: 51.09%, Val Acc: 84.81%, Time: 101.6s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 9/18\nNew best validation accuracy: 85.88%\nFold 0, Epoch [9/18] Loss: 1.0007, Train Acc: 55.33%, Val Acc: 85.88%, Time: 103.3s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 10/18\nNew best validation accuracy: 88.44%\nFold 0, Epoch [10/18] Loss: 1.0969, Train Acc: 52.96%, Val Acc: 88.44%, Time: 103.5s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 11/18\nNew best validation accuracy: 90.25%\nFold 0, Epoch [11/18] Loss: 0.9755, Train Acc: 56.80%, Val Acc: 90.25%, Time: 103.5s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 12/18\nFold 0, Epoch [12/18] Loss: 0.9920, Train Acc: 58.13%, Val Acc: 89.38%, Time: 105.2s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 13/18\nNew best validation accuracy: 91.31%\nFold 0, Epoch [13/18] Loss: 0.9051, Train Acc: 59.01%, Val Acc: 91.31%, Time: 104.9s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 14/18\nFold 0, Epoch [14/18] Loss: 0.8684, Train Acc: 60.02%, Val Acc: 91.06%, Time: 102.7s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 15/18\nFold 0, Epoch [15/18] Loss: 0.8806, Train Acc: 60.74%, Val Acc: 89.94%, Time: 103.5s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 16/18\nNew best validation accuracy: 91.81%\nFold 0, Epoch [16/18] Loss: 0.7501, Train Acc: 62.04%, Val Acc: 91.81%, Time: 104.5s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 17/18\nFold 0, Epoch [17/18] Loss: 0.8968, Train Acc: 60.18%, Val Acc: 91.00%, Time: 103.0s\nCheckpoint saved: checkpoints/fold_0_latest.pth\nStarting epoch 18/18\nFold 0, Epoch [18/18] Loss: 0.7355, Train Acc: 63.79%, Val Acc: 91.06%, Time: 103.0s\nCheckpoint saved: checkpoints/fold_0_latest.pth\n=== Training fold 2/4 ===\nStarting robust CNN training for fold 1\nFound 20 classes: ['AK' 'ALA_IDRIS' 'ARBORIO' 'BASMATI' 'BD30' 'BD72' 'BD95' 'BINADHAN16'\n 'BINADHAN25' 'BINADHAN7' 'BR22' 'BRRI67' 'BUZGULU' 'DIMNIT' 'IPSALA'\n 'JASMINE' 'KARACADAG' 'KIRMIZI' 'NAZLI' 'SIIRT']\nUsing StratifiedKFold for splitting data\nStarting epoch 1/18\nNew best validation accuracy: 36.56%\nFold 1, Epoch [1/18] Loss: 3.3059, Train Acc: 8.84%, Val Acc: 36.56%, Time: 101.9s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 2/18\nNew best validation accuracy: 55.62%\nFold 1, Epoch [2/18] Loss: 2.5866, Train Acc: 16.87%, Val Acc: 55.62%, Time: 102.0s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 3/18\nNew best validation accuracy: 69.06%\nFold 1, Epoch [3/18] Loss: 2.0906, Train Acc: 25.78%, Val Acc: 69.06%, Time: 101.5s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 4/18\nNew best validation accuracy: 74.19%\nFold 1, Epoch [4/18] Loss: 1.7693, Train Acc: 33.83%, Val Acc: 74.19%, Time: 102.5s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 5/18\nNew best validation accuracy: 77.88%\nFold 1, Epoch [5/18] Loss: 1.5836, Train Acc: 39.13%, Val Acc: 77.88%, Time: 101.3s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 6/18\nNew best validation accuracy: 82.56%\nFold 1, Epoch [6/18] Loss: 1.3835, Train Acc: 45.14%, Val Acc: 82.56%, Time: 101.8s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 7/18\nNew best validation accuracy: 86.06%\nFold 1, Epoch [7/18] Loss: 1.2917, Train Acc: 47.88%, Val Acc: 86.06%, Time: 103.8s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 8/18\nNew best validation accuracy: 88.50%\nFold 1, Epoch [8/18] Loss: 1.2127, Train Acc: 47.88%, Val Acc: 88.50%, Time: 103.5s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 9/18\nFold 1, Epoch [9/18] Loss: 1.1680, Train Acc: 50.14%, Val Acc: 88.31%, Time: 101.7s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 10/18\nNew best validation accuracy: 89.62%\nFold 1, Epoch [10/18] Loss: 1.1109, Train Acc: 54.21%, Val Acc: 89.62%, Time: 101.5s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 11/18\nFold 1, Epoch [11/18] Loss: 1.0607, Train Acc: 54.87%, Val Acc: 89.44%, Time: 101.0s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 12/18\nNew best validation accuracy: 91.62%\nFold 1, Epoch [12/18] Loss: 1.0281, Train Acc: 55.60%, Val Acc: 91.62%, Time: 101.7s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 13/18\nFold 1, Epoch [13/18] Loss: 0.9159, Train Acc: 59.41%, Val Acc: 91.19%, Time: 100.9s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 14/18\nNew best validation accuracy: 93.06%\nFold 1, Epoch [14/18] Loss: 0.8427, Train Acc: 62.26%, Val Acc: 93.06%, Time: 101.2s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 15/18\nFold 1, Epoch [15/18] Loss: 0.8549, Train Acc: 61.78%, Val Acc: 92.56%, Time: 101.0s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 16/18\nFold 1, Epoch [16/18] Loss: 0.8411, Train Acc: 61.69%, Val Acc: 92.44%, Time: 101.5s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 17/18\nNew best validation accuracy: 93.50%\nFold 1, Epoch [17/18] Loss: 0.7789, Train Acc: 61.15%, Val Acc: 93.50%, Time: 101.4s\nCheckpoint saved: checkpoints/fold_1_latest.pth\nStarting epoch 18/18\nNew best validation accuracy: 94.38%\nFold 1, Epoch [18/18] Loss: 0.7209, Train Acc: 64.48%, Val Acc: 94.38%, Time: 101.3s\nCheckpoint saved: checkpoints/fold_1_latest.pth\n=== Training fold 3/4 ===\nStarting robust CNN training for fold 2\nFound 20 classes: ['AK' 'ALA_IDRIS' 'ARBORIO' 'BASMATI' 'BD30' 'BD72' 'BD95' 'BINADHAN16'\n 'BINADHAN25' 'BINADHAN7' 'BR22' 'BRRI67' 'BUZGULU' 'DIMNIT' 'IPSALA'\n 'JASMINE' 'KARACADAG' 'KIRMIZI' 'NAZLI' 'SIIRT']\nUsing StratifiedKFold for splitting data\nStarting epoch 1/18\nNew best validation accuracy: 33.62%\nFold 2, Epoch [1/18] Loss: 3.3316, Train Acc: 8.26%, Val Acc: 33.62%, Time: 100.5s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 2/18\nNew best validation accuracy: 54.87%\nFold 2, Epoch [2/18] Loss: 2.5903, Train Acc: 17.34%, Val Acc: 54.87%, Time: 100.9s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 3/18\nNew best validation accuracy: 64.38%\nFold 2, Epoch [3/18] Loss: 2.1281, Train Acc: 26.89%, Val Acc: 64.38%, Time: 101.4s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 4/18\nNew best validation accuracy: 70.94%\nFold 2, Epoch [4/18] Loss: 1.7311, Train Acc: 35.67%, Val Acc: 70.94%, Time: 101.3s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 5/18\nNew best validation accuracy: 74.81%\nFold 2, Epoch [5/18] Loss: 1.4732, Train Acc: 41.20%, Val Acc: 74.81%, Time: 101.1s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 6/18\nNew best validation accuracy: 78.62%\nFold 2, Epoch [6/18] Loss: 1.3902, Train Acc: 44.95%, Val Acc: 78.62%, Time: 101.6s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 7/18\nNew best validation accuracy: 81.31%\nFold 2, Epoch [7/18] Loss: 1.2325, Train Acc: 49.26%, Val Acc: 81.31%, Time: 101.8s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 8/18\nNew best validation accuracy: 83.94%\nFold 2, Epoch [8/18] Loss: 1.2056, Train Acc: 49.68%, Val Acc: 83.94%, Time: 101.6s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 9/18\nNew best validation accuracy: 87.56%\nFold 2, Epoch [9/18] Loss: 1.0819, Train Acc: 53.42%, Val Acc: 87.56%, Time: 102.0s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 10/18\nFold 2, Epoch [10/18] Loss: 1.0331, Train Acc: 56.21%, Val Acc: 87.19%, Time: 103.1s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 11/18\nNew best validation accuracy: 90.69%\nFold 2, Epoch [11/18] Loss: 1.0204, Train Acc: 56.83%, Val Acc: 90.69%, Time: 100.8s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 12/18\nNew best validation accuracy: 91.06%\nFold 2, Epoch [12/18] Loss: 1.0034, Train Acc: 57.96%, Val Acc: 91.06%, Time: 100.7s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 13/18\nNew best validation accuracy: 91.38%\nFold 2, Epoch [13/18] Loss: 0.8374, Train Acc: 62.50%, Val Acc: 91.38%, Time: 101.6s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 14/18\nNew best validation accuracy: 92.12%\nFold 2, Epoch [14/18] Loss: 0.8882, Train Acc: 60.90%, Val Acc: 92.12%, Time: 101.3s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 15/18\nNew best validation accuracy: 93.06%\nFold 2, Epoch [15/18] Loss: 0.8152, Train Acc: 63.36%, Val Acc: 93.06%, Time: 101.2s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 16/18\nFold 2, Epoch [16/18] Loss: 0.7545, Train Acc: 65.78%, Val Acc: 92.62%, Time: 101.2s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 17/18\nNew best validation accuracy: 94.25%\nFold 2, Epoch [17/18] Loss: 0.7546, Train Acc: 64.20%, Val Acc: 94.25%, Time: 100.9s\nCheckpoint saved: checkpoints/fold_2_latest.pth\nStarting epoch 18/18\nFold 2, Epoch [18/18] Loss: 0.7768, Train Acc: 62.57%, Val Acc: 91.69%, Time: 100.1s\nCheckpoint saved: checkpoints/fold_2_latest.pth\n=== Training fold 4/4 ===\nStarting robust CNN training for fold 3\nFound 20 classes: ['AK' 'ALA_IDRIS' 'ARBORIO' 'BASMATI' 'BD30' 'BD72' 'BD95' 'BINADHAN16'\n 'BINADHAN25' 'BINADHAN7' 'BR22' 'BRRI67' 'BUZGULU' 'DIMNIT' 'IPSALA'\n 'JASMINE' 'KARACADAG' 'KIRMIZI' 'NAZLI' 'SIIRT']\nUsing StratifiedKFold for splitting data\nStarting epoch 1/18\nNew best validation accuracy: 42.19%\nFold 3, Epoch [1/18] Loss: 3.3710, Train Acc: 7.69%, Val Acc: 42.19%, Time: 101.0s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 2/18\nNew best validation accuracy: 60.00%\nFold 3, Epoch [2/18] Loss: 2.5596, Train Acc: 17.08%, Val Acc: 60.00%, Time: 101.0s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 3/18\nNew best validation accuracy: 68.31%\nFold 3, Epoch [3/18] Loss: 1.9981, Train Acc: 27.62%, Val Acc: 68.31%, Time: 100.8s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 4/18\nNew best validation accuracy: 74.94%\nFold 3, Epoch [4/18] Loss: 1.7789, Train Acc: 34.23%, Val Acc: 74.94%, Time: 101.3s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 5/18\nNew best validation accuracy: 78.94%\nFold 3, Epoch [5/18] Loss: 1.5089, Train Acc: 40.86%, Val Acc: 78.94%, Time: 101.1s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 6/18\nNew best validation accuracy: 82.44%\nFold 3, Epoch [6/18] Loss: 1.3582, Train Acc: 45.51%, Val Acc: 82.44%, Time: 101.1s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 7/18\nNew best validation accuracy: 83.81%\nFold 3, Epoch [7/18] Loss: 1.2485, Train Acc: 47.96%, Val Acc: 83.81%, Time: 101.4s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 8/18\nNew best validation accuracy: 84.44%\nFold 3, Epoch [8/18] Loss: 1.2575, Train Acc: 50.24%, Val Acc: 84.44%, Time: 100.4s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 9/18\nNew best validation accuracy: 87.62%\nFold 3, Epoch [9/18] Loss: 1.0561, Train Acc: 52.87%, Val Acc: 87.62%, Time: 103.2s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 10/18\nFold 3, Epoch [10/18] Loss: 1.0065, Train Acc: 57.15%, Val Acc: 87.00%, Time: 101.1s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 11/18\nFold 3, Epoch [11/18] Loss: 0.9571, Train Acc: 58.60%, Val Acc: 87.56%, Time: 99.7s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 12/18\nFold 3, Epoch [12/18] Loss: 0.9404, Train Acc: 56.57%, Val Acc: 86.88%, Time: 100.1s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 13/18\nFold 3, Epoch [13/18] Loss: 0.9091, Train Acc: 58.36%, Val Acc: 87.06%, Time: 100.7s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 14/18\nFold 3, Epoch [14/18] Loss: 0.8514, Train Acc: 61.31%, Val Acc: 86.50%, Time: 101.0s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 15/18\nNew best validation accuracy: 88.38%\nFold 3, Epoch [15/18] Loss: 0.7931, Train Acc: 61.57%, Val Acc: 88.38%, Time: 100.8s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 16/18\nNew best validation accuracy: 90.06%\nFold 3, Epoch [16/18] Loss: 0.7847, Train Acc: 64.46%, Val Acc: 90.06%, Time: 101.5s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 17/18\nFold 3, Epoch [17/18] Loss: 0.7552, Train Acc: 64.11%, Val Acc: 88.69%, Time: 100.9s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nStarting epoch 18/18\nFold 3, Epoch [18/18] Loss: 0.8245, Train Acc: 62.38%, Val Acc: 88.94%, Time: 101.3s\nCheckpoint saved: checkpoints/fold_3_latest.pth\nExtracting features for XGBoost training...\nExtracting features from fold 1\nExtracting features from fold 2\nExtracting features from fold 3\nExtracting features from fold 4\nTraining XGBoost ensemble...\nMaking ensemble predictions with CNN + XGBoost...\nGetting predictions from fold 1 (weight: 0.250)\nMaking predictions with TTA...\nProcessed 1/1600 images\nProcessed 51/1600 images\nProcessed 101/1600 images\nProcessed 151/1600 images\nProcessed 201/1600 images\nProcessed 251/1600 images\nProcessed 301/1600 images\nProcessed 351/1600 images\nProcessed 401/1600 images\nProcessed 451/1600 images\nProcessed 501/1600 images\nProcessed 551/1600 images\nProcessed 601/1600 images\nProcessed 651/1600 images\nProcessed 701/1600 images\nProcessed 751/1600 images\nProcessed 801/1600 images\nProcessed 851/1600 images\nProcessed 901/1600 images\nProcessed 951/1600 images\nProcessed 1001/1600 images\nProcessed 1051/1600 images\nProcessed 1101/1600 images\nProcessed 1151/1600 images\nProcessed 1201/1600 images\nProcessed 1251/1600 images\nProcessed 1301/1600 images\nProcessed 1351/1600 images\nProcessed 1401/1600 images\nProcessed 1451/1600 images\nProcessed 1501/1600 images\nProcessed 1551/1600 images\nGetting predictions from fold 2 (weight: 0.250)\nMaking predictions with TTA...\nProcessed 1/1600 images\nProcessed 51/1600 images\nProcessed 101/1600 images\nProcessed 151/1600 images\nProcessed 201/1600 images\nProcessed 251/1600 images\nProcessed 301/1600 images\nProcessed 351/1600 images\nProcessed 401/1600 images\nProcessed 451/1600 images\nProcessed 501/1600 images\nProcessed 551/1600 images\nProcessed 601/1600 images\nProcessed 651/1600 images\nProcessed 701/1600 images\nProcessed 751/1600 images\nProcessed 801/1600 images\nProcessed 851/1600 images\nProcessed 901/1600 images\nProcessed 951/1600 images\nProcessed 1001/1600 images\nProcessed 1051/1600 images\nProcessed 1101/1600 images\nProcessed 1151/1600 images\nProcessed 1201/1600 images\nProcessed 1251/1600 images\nProcessed 1301/1600 images\nProcessed 1351/1600 images\nProcessed 1401/1600 images\nProcessed 1451/1600 images\nProcessed 1501/1600 images\nProcessed 1551/1600 images\nGetting predictions from fold 3 (weight: 0.250)\nMaking predictions with TTA...\nProcessed 1/1600 images\nProcessed 51/1600 images\nProcessed 101/1600 images\nProcessed 151/1600 images\nProcessed 201/1600 images\nProcessed 251/1600 images\nProcessed 301/1600 images\nProcessed 351/1600 images\nProcessed 401/1600 images\nProcessed 451/1600 images\nProcessed 501/1600 images\nProcessed 551/1600 images\nProcessed 601/1600 images\nProcessed 651/1600 images\nProcessed 701/1600 images\nProcessed 751/1600 images\nProcessed 801/1600 images\nProcessed 851/1600 images\nProcessed 901/1600 images\nProcessed 951/1600 images\nProcessed 1001/1600 images\nProcessed 1051/1600 images\nProcessed 1101/1600 images\nProcessed 1151/1600 images\nProcessed 1201/1600 images\nProcessed 1251/1600 images\nProcessed 1301/1600 images\nProcessed 1351/1600 images\nProcessed 1401/1600 images\nProcessed 1451/1600 images\nProcessed 1501/1600 images\nProcessed 1551/1600 images\nGetting predictions from fold 4 (weight: 0.250)\nMaking predictions with TTA...\nProcessed 1/1600 images\nProcessed 51/1600 images\nProcessed 101/1600 images\nProcessed 151/1600 images\nProcessed 201/1600 images\nProcessed 251/1600 images\nProcessed 301/1600 images\nProcessed 351/1600 images\nProcessed 401/1600 images\nProcessed 451/1600 images\nProcessed 501/1600 images\nProcessed 551/1600 images\nProcessed 601/1600 images\nProcessed 651/1600 images\nProcessed 701/1600 images\nProcessed 751/1600 images\nProcessed 801/1600 images\nProcessed 851/1600 images\nProcessed 901/1600 images\nProcessed 951/1600 images\nProcessed 1001/1600 images\nProcessed 1051/1600 images\nProcessed 1101/1600 images\nProcessed 1151/1600 images\nProcessed 1201/1600 images\nProcessed 1251/1600 images\nProcessed 1301/1600 images\nProcessed 1351/1600 images\nProcessed 1401/1600 images\nProcessed 1451/1600 images\nProcessed 1501/1600 images\nProcessed 1551/1600 images\nSubmission file saved as submission.csv\nTraining pipeline completed successfully!\nSubmission file created: submission.csv\nAll checkpoints saved in: checkpoints/\nTraining logs available in the log file\nSubmission Summary:\nTotal predictions: 1600\nUnique classes predicted: 20\nMost predicted class: BD95\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "TrIogWtxsKLj"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}