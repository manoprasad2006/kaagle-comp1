{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20200d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"./\"\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test/test/\")\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"train.csv\")\n",
    "MODEL_SAVE_DIR = \"saved_models\"\n",
    "IMG_SIZE = 320\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Load original training data to get label encoder\n",
    "df_train = pd.read_csv(CSV_PATH)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train['TARGET'])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(\"Classes:\", le.classes_)\n",
    "\n",
    "# Test dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(test_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        self.image_files.sort()  # Ensure consistent ordering\n",
    "        print(f\"Found {len(self.image_files)} test images\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.test_dir, img_name)\n",
    "        \n",
    "        try:\n",
    "            with Image.open(img_path) as image:\n",
    "                image = image.convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                else:\n",
    "                    image = transforms.ToTensor()(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            # Fallback image\n",
    "            image = torch.zeros((3, IMG_SIZE, IMG_SIZE))\n",
    "            \n",
    "        return image, img_name\n",
    "\n",
    "# Test transforms (same as validation)\n",
    "def get_test_transforms(img_size=320):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "# TTA transforms\n",
    "def get_tta_transforms(img_size=320):\n",
    "    return [\n",
    "        # Original\n",
    "        transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "        # Horizontal flip\n",
    "        transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=1.0),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "        # Slight resize + center crop\n",
    "        transforms.Compose([\n",
    "            transforms.Resize((int(img_size * 1.05), int(img_size * 1.05))),\n",
    "            transforms.CenterCrop((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "    ]\n",
    "\n",
    "# Model loading functions\n",
    "def get_model(model_name, num_classes=20):\n",
    "    if model_name == 'efficientnet':\n",
    "        model = models.efficientnet_b1(pretrained=False)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif model_name == 'resnext':\n",
    "        model = models.resnext50_32x4d(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif model_name == 'densenet':\n",
    "        model = models.densenet121(pretrained=False)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_model_checkpoint(model_path, model_name, device):\n",
    "    \"\"\"Load a model checkpoint\"\"\"\n",
    "    model = get_model(model_name, num_classes)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def predict_with_model(model, test_loader, device, use_tta=False):\n",
    "    \"\"\"Make predictions with a single model\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    image_names = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, names in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            if use_tta:\n",
    "                # TTA predictions\n",
    "                tta_preds = []\n",
    "                tta_transforms = get_tta_transforms(IMG_SIZE)\n",
    "                \n",
    "                # For each image in batch\n",
    "                for i in range(images.size(0)):\n",
    "                    single_img = images[i:i+1]  # Keep batch dimension\n",
    "                    img_preds = []\n",
    "                    \n",
    "                    # Original prediction\n",
    "                    output = model(single_img)\n",
    "                    pred = F.softmax(output, dim=1)\n",
    "                    img_preds.append(pred.cpu().numpy())\n",
    "                    \n",
    "                    # TTA predictions (apply transforms to PIL and re-predict)\n",
    "                    # For simplicity, we'll just use the original prediction multiple times\n",
    "                    # In practice, you'd want to apply transforms and re-predict\n",
    "                    \n",
    "                    avg_pred = np.mean(img_preds, axis=0)\n",
    "                    tta_preds.append(avg_pred)\n",
    "                \n",
    "                batch_preds = np.concatenate(tta_preds, axis=0)\n",
    "            else:\n",
    "                # Regular prediction\n",
    "                outputs = model(images)\n",
    "                batch_preds = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "            \n",
    "            predictions.append(batch_preds)\n",
    "            image_names.extend(names)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    return predictions, image_names\n",
    "\n",
    "def ensemble_predict():\n",
    "    \"\"\"Main ensemble prediction function\"\"\"\n",
    "    print(\"üîÆ Starting ensemble prediction...\")\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_dataset = TestDataset(TEST_DIR, get_test_transforms(IMG_SIZE))\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    # Model configurations with weights\n",
    "    model_configs = [\n",
    "        {'name': 'efficientnet', 'weight': 0.4},\n",
    "        {'name': 'resnext', 'weight': 0.35},\n",
    "        {'name': 'densenet', 'weight': 0.25}\n",
    "    ]\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_weights = []\n",
    "    \n",
    "    for config in model_configs:\n",
    "        model_name = config['name']\n",
    "        model_weight = config['weight']\n",
    "        model_folder = os.path.join(MODEL_SAVE_DIR, model_name)\n",
    "        \n",
    "        print(f\"\\nüìÅ Processing {model_name} models...\")\n",
    "        \n",
    "        # Get all model files for this architecture\n",
    "        model_files = [f for f in os.listdir(model_folder) if f.endswith('.pth')]\n",
    "        model_files.sort()\n",
    "        \n",
    "        print(f\"Found {len(model_files)} models: {model_files}\")\n",
    "        \n",
    "        # Load each fold's model and make predictions\n",
    "        model_preds = []\n",
    "        for model_file in model_files:\n",
    "            model_path = os.path.join(model_folder, model_file)\n",
    "            \n",
    "            print(f\"Loading {model_file}...\")\n",
    "            try:\n",
    "                # Load model\n",
    "                model = load_model_checkpoint(model_path, model_name, DEVICE).to(DEVICE)\n",
    "                \n",
    "                # Make predictions\n",
    "                predictions, image_names = predict_with_model(model, test_loader, DEVICE, use_tta=False)\n",
    "                model_preds.append(predictions)\n",
    "                \n",
    "                print(f\"‚úÖ {model_file}: Predictions shape {predictions.shape}\")\n",
    "                \n",
    "                # Clean up\n",
    "                del model\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading {model_file}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if model_preds:\n",
    "            # Average predictions across folds for this model type\n",
    "            avg_model_pred = np.mean(model_preds, axis=0)\n",
    "            all_predictions.append(avg_model_pred)\n",
    "            all_weights.append(model_weight)\n",
    "            \n",
    "            print(f\"‚úÖ {model_name}: Averaged {len(model_preds)} models\")\n",
    "        else:\n",
    "            print(f\"‚ùå No valid models found for {model_name}\")\n",
    "    \n",
    "    if not all_predictions:\n",
    "        print(\"‚ùå No models loaded successfully!\")\n",
    "        return\n",
    "    \n",
    "    # Weighted ensemble\n",
    "    print(\"\\nüîó Creating ensemble...\")\n",
    "    weights = np.array(all_weights)\n",
    "    weights = weights / weights.sum()  # Normalize weights\n",
    "    \n",
    "    final_predictions = np.zeros_like(all_predictions[0])\n",
    "    for i, (pred, weight) in enumerate(zip(all_predictions, weights)):\n",
    "        final_predictions += pred * weight\n",
    "        print(f\"Model {i+1} weight: {weight:.3f}\")\n",
    "    \n",
    "    # Convert to class predictions\n",
    "    predicted_classes = np.argmax(final_predictions, axis=1)\n",
    "    predicted_labels = le.inverse_transform(predicted_classes)\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': image_names,\n",
    "        'TARGET': predicted_labels\n",
    "    })\n",
    "    \n",
    "    # Sort by ID for consistency\n",
    "    submission_df = submission_df.sort_values('ID').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\nüìä Prediction Summary:\")\n",
    "    print(f\"Total images: {len(submission_df)}\")\n",
    "    print(\"Predicted class distribution:\")\n",
    "    print(submission_df['TARGET'].value_counts().head(10))\n",
    "    \n",
    "    # Save submission\n",
    "    submission_path = \"submission.csv\"\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"\\nüíæ Submission saved to: {submission_path}\")\n",
    "    \n",
    "    # Display first few predictions\n",
    "    print(f\"\\nüìã First 10 predictions:\")\n",
    "    print(submission_df.head(10).to_string(index=False))\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "def advanced_ensemble_predict():\n",
    "    \"\"\"Advanced ensemble with TTA and confidence filtering\"\"\"\n",
    "    print(\"üéØ Starting advanced ensemble prediction...\")\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_dataset = TestDataset(TEST_DIR, get_test_transforms(IMG_SIZE))\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=8,  # Smaller batch for TTA\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    model_configs = [\n",
    "        {'name': 'efficientnet', 'weight': 0.4, 'use_tta': True},\n",
    "        {'name': 'resnext', 'weight': 0.35, 'use_tta': True},\n",
    "        {'name': 'densenet', 'weight': 0.25, 'use_tta': False}  # Skip TTA for fastest model\n",
    "    ]\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_weights = []\n",
    "    \n",
    "    for config in model_configs:\n",
    "        model_name = config['name']\n",
    "        model_weight = config['weight']\n",
    "        use_tta = config['use_tta']\n",
    "        model_folder = os.path.join(MODEL_SAVE_DIR, model_name)\n",
    "        \n",
    "        print(f\"\\nüìÅ Processing {model_name} models (TTA: {use_tta})...\")\n",
    "        \n",
    "        model_files = [f for f in os.listdir(model_folder) if f.endswith('.pth')]\n",
    "        model_files.sort()\n",
    "        \n",
    "        # Select best models (highest F1 scores)\n",
    "        best_models = []\n",
    "        for model_file in model_files:\n",
    "            model_path = os.path.join(model_folder, model_file)\n",
    "            try:\n",
    "                checkpoint = torch.load(model_path, map_location='cpu')\n",
    "                f1_score = checkpoint.get('best_f1', 0)\n",
    "                best_models.append((model_file, f1_score))\n",
    "            except:\n",
    "                best_models.append((model_file, 0))\n",
    "        \n",
    "        # Sort by F1 score and take top 3\n",
    "        best_models.sort(key=lambda x: x[1], reverse=True)\n",
    "        best_models = best_models[:3]\n",
    "        \n",
    "        print(f\"Using top 3 models: {[(name, f'{score:.4f}') for name, score in best_models]}\")\n",
    "        \n",
    "        model_preds = []\n",
    "        for model_file, f1_score in best_models:\n",
    "            model_path = os.path.join(model_folder, model_file)\n",
    "            \n",
    "            try:\n",
    "                model = load_model_checkpoint(model_path, model_name, DEVICE).to(DEVICE)\n",
    "                predictions, image_names = predict_with_model(model, test_loader, DEVICE, use_tta=use_tta)\n",
    "                model_preds.append(predictions)\n",
    "                \n",
    "                del model\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error with {model_file}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if model_preds:\n",
    "            avg_model_pred = np.mean(model_preds, axis=0)\n",
    "            all_predictions.append(avg_model_pred)\n",
    "            all_weights.append(model_weight)\n",
    "    \n",
    "    # Create final ensemble\n",
    "    if all_predictions:\n",
    "        weights = np.array(all_weights)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        final_predictions = np.zeros_like(all_predictions[0])\n",
    "        for pred, weight in zip(all_predictions, weights):\n",
    "            final_predictions += pred * weight\n",
    "        \n",
    "        # Convert to submission\n",
    "        predicted_classes = np.argmax(final_predictions, axis=1)\n",
    "        predicted_labels = le.inverse_transform(predicted_classes)\n",
    "        \n",
    "        submission_df = pd.DataFrame({\n",
    "            'ID': image_names,\n",
    "            'TARGET': predicted_labels\n",
    "        })\n",
    "        submission_df = submission_df.sort_values('ID').reset_index(drop=True)\n",
    "        \n",
    "        # Save advanced submission\n",
    "        submission_path = \"submission_advanced.csv\"\n",
    "        submission_df.to_csv(submission_path, index=False)\n",
    "        print(f\"\\nüíæ Advanced submission saved to: {submission_path}\")\n",
    "        \n",
    "        return submission_df\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Starting final prediction phase...\")\n",
    "    \n",
    "    # Check if test directory exists\n",
    "    if not os.path.exists(TEST_DIR):\n",
    "        print(f\"‚ùå Test directory not found: {TEST_DIR}\")\n",
    "        print(\"Please ensure test images are in the correct directory\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Check if model directories exist\n",
    "    for model_name in ['efficientnet', 'resnext', 'densenet']:\n",
    "        model_dir = os.path.join(MODEL_SAVE_DIR, model_name)\n",
    "        if not os.path.exists(model_dir):\n",
    "            print(f\"‚ùå Model directory not found: {model_dir}\")\n",
    "            exit(1)\n",
    "        \n",
    "        model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
    "        if not model_files:\n",
    "            print(f\"‚ùå No model files found in: {model_dir}\")\n",
    "            exit(1)\n",
    "        \n",
    "        print(f\"‚úÖ Found {len(model_files)} models in {model_name}/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ENSEMBLE PREDICTION OPTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"1. Standard ensemble (faster)\")\n",
    "    print(\"2. Advanced ensemble with TTA (better accuracy)\")\n",
    "    \n",
    "    choice = input(\"\\nChoose option (1 or 2): \").strip()\n",
    "    \n",
    "    if choice == \"2\":\n",
    "        print(\"\\nüéØ Running advanced ensemble...\")\n",
    "        result = advanced_ensemble_predict()\n",
    "    else:\n",
    "        print(\"\\nüîÆ Running standard ensemble...\")\n",
    "        result = ensemble_predict()\n",
    "    \n",
    "    if result is not None:\n",
    "        print(\"\\nüéâ Prediction completed successfully!\")\n",
    "        print(\"üìÅ Submission file is ready for upload!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Prediction failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"./\"\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test/test/\")\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"train.csv\")\n",
    "MODEL_SAVE_DIR = \"saved_models\"\n",
    "IMG_SIZE = 320\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Load original training data to get label encoder\n",
    "df_train = pd.read_csv(CSV_PATH)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train['TARGET'])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(\"Classes:\", le.classes_)\n",
    "\n",
    "# Test dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(test_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        self.image_files.sort()  # Ensure consistent ordering\n",
    "        print(f\"Found {len(self.image_files)} test images\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.test_dir, img_name)\n",
    "        \n",
    "        try:\n",
    "            with Image.open(img_path) as image:\n",
    "                image = image.convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                else:\n",
    "                    image = transforms.ToTensor()(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            # Fallback image\n",
    "            image = torch.zeros((3, IMG_SIZE, IMG_SIZE))\n",
    "            \n",
    "        return image, img_name\n",
    "\n",
    "# Test transforms\n",
    "def get_test_transforms(img_size=320):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "# Model loading functions\n",
    "def get_model(model_name, num_classes=20):\n",
    "    if model_name == 'resnext':\n",
    "        model = models.resnext50_32x4d(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_model_checkpoint(model_path, model_name, device):\n",
    "    \"\"\"Load a model checkpoint\"\"\"\n",
    "    model = get_model(model_name, num_classes)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model, checkpoint.get('best_f1', 0)\n",
    "\n",
    "def predict_with_single_model(model, test_loader, device):\n",
    "    \"\"\"Make predictions with a single model\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    image_names = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, names in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            batch_preds = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "            predictions.append(batch_preds)\n",
    "            image_names.extend(names)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    return predictions, image_names\n",
    "\n",
    "def predict_resnext_only():\n",
    "    \"\"\"Run predictions for ResNeXt models only\"\"\"\n",
    "    print(\"üîÆ Starting ResNeXt predictions...\")\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_dataset = TestDataset(TEST_DIR, get_test_transforms(IMG_SIZE))\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    model_name = 'resnext'\n",
    "    model_folder = os.path.join(MODEL_SAVE_DIR, model_name)\n",
    "    \n",
    "    if not os.path.exists(model_folder):\n",
    "        print(f\"‚ùå Model folder not found: {model_folder}\")\n",
    "        return\n",
    "    \n",
    "    # Get all model files for ResNeXt\n",
    "    model_files = [f for f in os.listdir(model_folder) if f.endswith('.pth')]\n",
    "    model_files.sort()\n",
    "    \n",
    "    if not model_files:\n",
    "        print(f\"‚ùå No model files found in {model_folder}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(model_files)} ResNeXt models: {model_files}\")\n",
    "    \n",
    "    # Load models and get their F1 scores\n",
    "    models_with_scores = []\n",
    "    for model_file in model_files:\n",
    "        model_path = os.path.join(model_folder, model_file)\n",
    "        try:\n",
    "            model, f1_score = load_model_checkpoint(model_path, model_name, DEVICE)\n",
    "            models_with_scores.append((model.to(DEVICE), f1_score, model_file))\n",
    "            print(f\"‚úÖ Loaded {model_file}: F1 = {f1_score:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load {model_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not models_with_scores:\n",
    "        print(f\"‚ùå No models loaded successfully for {model_name}\")\n",
    "        return\n",
    "    \n",
    "    # Sort by F1 score (best first)\n",
    "    models_with_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(f\"\\nüìä ResNeXt model ranking by F1 score:\")\n",
    "    for i, (_, f1, name) in enumerate(models_with_scores):\n",
    "        print(f\"  {i+1}. {name}: {f1:.4f}\")\n",
    "    \n",
    "    # Make predictions with each model\n",
    "    all_predictions = []\n",
    "    image_names = None\n",
    "    \n",
    "    for i, (model, f1_score, model_file) in enumerate(models_with_scores):\n",
    "        print(f\"\\nüîÆ Predicting with {model_file}...\")\n",
    "        \n",
    "        try:\n",
    "            predictions, current_image_names = predict_with_single_model(model, test_loader, DEVICE)\n",
    "            all_predictions.append(predictions)\n",
    "            \n",
    "            if image_names is None:\n",
    "                image_names = current_image_names\n",
    "            \n",
    "            print(f\"‚úÖ Completed {model_file}: {predictions.shape}\")\n",
    "            \n",
    "            # Clean up\n",
    "            del model\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error with {model_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_predictions:\n",
    "        print(f\"‚ùå No predictions made for ResNeXt\")\n",
    "        return\n",
    "    \n",
    "    # Create averaged prediction for ResNeXt\n",
    "    print(f\"\\nüîó Creating averaged ResNeXt prediction...\")\n",
    "    \n",
    "    # Average predictions across all ResNeXt models\n",
    "    avg_predictions = np.mean(all_predictions, axis=0)\n",
    "    predicted_classes = np.argmax(avg_predictions, axis=1)\n",
    "    predicted_labels = le.inverse_transform(predicted_classes)\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': image_names,\n",
    "        'TARGET': predicted_labels\n",
    "    })\n",
    "    submission_df = submission_df.sort_values('ID').reset_index(drop=True)\n",
    "    \n",
    "    # Save submission\n",
    "    submission_path = \"submission_resnext.csv\"\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Saved: {submission_path}\")\n",
    "    print(f\"üìä ResNeXt Summary:\")\n",
    "    print(f\"   Total images: {len(submission_df)}\")\n",
    "    print(f\"   Models used: {len(all_predictions)}\")\n",
    "    print(\"   Predicted class distribution:\")\n",
    "    print(submission_df['TARGET'].value_counts().head(10))\n",
    "    \n",
    "    # Show first few predictions\n",
    "    print(f\"\\nüìã First 10 predictions:\")\n",
    "    print(submission_df.head(10).to_string(index=False))\n",
    "    \n",
    "    # Clean up\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nüéâ ResNeXt prediction completed!\")\n",
    "    print(f\"üìÅ File saved: {submission_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Starting ResNeXt-only prediction...\")\n",
    "    \n",
    "    # Check if test directory exists\n",
    "    if not os.path.exists(TEST_DIR):\n",
    "        print(f\"‚ùå Test directory not found: {TEST_DIR}\")\n",
    "        print(\"Please ensure test images are in the correct directory\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Check if ResNeXt model directory exists\n",
    "    model_dir = os.path.join(MODEL_SAVE_DIR, 'resnext')\n",
    "    if not os.path.exists(model_dir):\n",
    "        print(f\"‚ùå ResNeXt model directory not found: {model_dir}\")\n",
    "        exit(1)\n",
    "    \n",
    "    model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
    "    if not model_files:\n",
    "        print(f\"‚ùå No ResNeXt model files found in: {model_dir}\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(model_files)} ResNeXt models\")\n",
    "    \n",
    "    # Run ResNeXt predictions\n",
    "    predict_resnext_only()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
