{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af34bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"./\"\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test/test/\")\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"train.csv\")\n",
    "MODEL_SAVE_DIR = \"saved_models\"\n",
    "IMG_SIZE = 384\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Load label encoder\n",
    "df_train = pd.read_csv(CSV_PATH)\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train['TARGET'])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Test dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(test_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        self.image_files.sort()\n",
    "        print(f\"Found {len(self.image_files)} test images\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.test_dir, img_name)\n",
    "        \n",
    "        try:\n",
    "            with Image.open(img_path) as image:\n",
    "                image = image.convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                else:\n",
    "                    image = transforms.ToTensor()(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            image = torch.zeros((3, IMG_SIZE, IMG_SIZE))\n",
    "            \n",
    "        return image, img_name\n",
    "\n",
    "# Model loading functions\n",
    "def get_model(model_name, num_classes=20):\n",
    "    if model_name == 'efficientnet':\n",
    "        model = models.efficientnet_b1(pretrained=False)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif model_name == 'resnext':\n",
    "        model = models.resnext50_32x4d(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif model_name == 'densenet':\n",
    "        model = models.densenet121(pretrained=False)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def quick_ensemble():\n",
    "    \"\"\"Quick ensemble of top 5 models - creates submission_quick_ensemble.csv\"\"\"\n",
    "    print(\"‚ö° QUICK ENSEMBLE: Top 5 models, no TTA (5 minutes)\")\n",
    "    \n",
    "    # Get all models with their F1 scores\n",
    "    all_models = []\n",
    "    for model_name in ['efficientnet', 'resnext', 'densenet']:\n",
    "        model_folder = os.path.join(MODEL_SAVE_DIR, model_name)\n",
    "        if os.path.exists(model_folder):\n",
    "            for model_file in os.listdir(model_folder):\n",
    "                if model_file.endswith('.pth'):\n",
    "                    try:\n",
    "                        model_path = os.path.join(model_folder, model_file)\n",
    "                        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "                        f1 = checkpoint.get('best_f1', 0)\n",
    "                        all_models.append((model_name, model_file, f1, model_path))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Skipping {model_file}: {e}\")\n",
    "                        continue\n",
    "    \n",
    "    if not all_models:\n",
    "        print(\"‚ùå No models found!\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by F1 score and take top 5\n",
    "    all_models.sort(key=lambda x: x[2], reverse=True)\n",
    "    top_models = all_models[:5]\n",
    "    \n",
    "    print(f\"\\nüìä Using top 5 models:\")\n",
    "    for i, (model_name, model_file, f1, _) in enumerate(top_models, 1):\n",
    "        print(f\"{i}. {model_name}/{model_file}: F1 = {f1:.4f}\")\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_dataset = TestDataset(TEST_DIR, transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    all_predictions = []\n",
    "    image_names = None\n",
    "    \n",
    "    # Make predictions with each model\n",
    "    for model_name, model_file, f1_score, model_path in top_models:\n",
    "        print(f\"\\nüîÆ Predicting with {model_name}/{model_file}...\")\n",
    "        \n",
    "        try:\n",
    "            # Load model\n",
    "            model = get_model(model_name, num_classes)\n",
    "            checkpoint = torch.load(model_path, map_location=DEVICE)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            model = model.to(DEVICE).eval()\n",
    "            \n",
    "            predictions = []\n",
    "            names = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, img_names in tqdm(test_loader, desc=f\"{model_name}\"):\n",
    "                    images = images.to(DEVICE)\n",
    "                    outputs = model(images)\n",
    "                    preds = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "                    predictions.append(preds)\n",
    "                    names.extend(img_names)\n",
    "            \n",
    "            predictions = np.concatenate(predictions, axis=0)\n",
    "            all_predictions.append(predictions)\n",
    "            \n",
    "            if image_names is None:\n",
    "                image_names = names\n",
    "            \n",
    "            print(f\"‚úÖ Completed: {predictions.shape}\")\n",
    "            \n",
    "            # Clean up\n",
    "            del model\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error with {model_name}/{model_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_predictions:\n",
    "        print(\"‚ùå No predictions generated!\")\n",
    "        return None\n",
    "    \n",
    "    # Weighted ensemble based on F1 scores\n",
    "    print(\"\\nüîó Creating weighted ensemble...\")\n",
    "    weights = np.array([f1 for _, _, f1, _ in top_models[:len(all_predictions)]])\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    print(\"Model weights:\")\n",
    "    for i, (name, file, f1, _) in enumerate(top_models[:len(all_predictions)]):\n",
    "        print(f\"  {name}: {weights[i]:.3f}\")\n",
    "    \n",
    "    final_predictions = np.zeros_like(all_predictions[0])\n",
    "    for pred, weight in zip(all_predictions, weights):\n",
    "        final_predictions += pred * weight\n",
    "    \n",
    "    # Convert to class predictions\n",
    "    predicted_classes = np.argmax(final_predictions, axis=1)\n",
    "    predicted_labels = le.inverse_transform(predicted_classes)\n",
    "    confidence_scores = np.max(final_predictions, axis=1)\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': image_names,\n",
    "        'TARGET': predicted_labels\n",
    "    })\n",
    "    \n",
    "    # Sort by ID\n",
    "    submission_df = submission_df.sort_values('ID').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\nüìä Quick Ensemble Results:\")\n",
    "    print(f\"Total images: {len(submission_df)}\")\n",
    "    print(f\"Average confidence: {confidence_scores.mean():.3f}\")\n",
    "    print(f\"Min confidence: {confidence_scores.min():.3f}\")\n",
    "    print(f\"Max confidence: {confidence_scores.max():.3f}\")\n",
    "    \n",
    "    print(\"\\nPredicted class distribution:\")\n",
    "    print(submission_df['TARGET'].value_counts().head(10))\n",
    "    \n",
    "    # Save submission\n",
    "    submission_path = \"submission_quick_ensemble.csv\"\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Submission saved: {submission_path}\")\n",
    "    print(f\"Expected boost: +1-2% F1 score\")\n",
    "    print(f\"Estimated score: 0.905-0.920\")\n",
    "    \n",
    "    # Show sample predictions\n",
    "    print(f\"\\nüìã First 10 predictions:\")\n",
    "    print(submission_df.head(10).to_string(index=False))\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Quick Ensemble Submission Generator\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if test directory exists\n",
    "    if not os.path.exists(TEST_DIR):\n",
    "        print(f\"‚ùå Test directory not found: {TEST_DIR}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Check if models exist\n",
    "    model_count = 0\n",
    "    for model_name in ['efficientnet', 'resnext', 'densenet']:\n",
    "        model_dir = os.path.join(MODEL_SAVE_DIR, model_name)\n",
    "        if os.path.exists(model_dir):\n",
    "            files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
    "            model_count += len(files)\n",
    "            print(f\"‚úÖ Found {len(files)} {model_name} models\")\n",
    "    \n",
    "    if model_count == 0:\n",
    "        print(\"‚ùå No models found!\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(f\"\\nTotal models available: {model_count}\")\n",
    "    print(\"\\nStarting quick ensemble prediction...\")\n",
    "    \n",
    "    result = quick_ensemble()\n",
    "    \n",
    "    if result is not None:\n",
    "        print(\"\\nüéâ Quick ensemble completed successfully!\")\n",
    "        print(\"üìÅ File ready: submission_quick_ensemble.csv\")\n",
    "        print(\"üöÄ Upload this file to the competition!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Quick ensemble failed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
