{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"./\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train/train/\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test/test/\")\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"train.csv\")\n",
    "\n",
    "BATCH_SIZE = 16  # Smaller batch size for stability\n",
    "EPOCHS = 15\n",
    "LR = 1e-4\n",
    "N_SPLITS = 5\n",
    "IMG_SIZE = 320  # Reasonable size\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set seeds\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "le = LabelEncoder()\n",
    "df['label_idx'] = le.fit_transform(df['TARGET'])\n",
    "df['image_id'] = df['ID']\n",
    "num_classes = df['label_idx'].nunique()\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(\"Class distribution:\")\n",
    "print(df['TARGET'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ef997",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple but effective dataset\n",
    "class ImprovedDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['image_id'])\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            # Return a blank image if loading fails\n",
    "            image = Image.new('RGB', (224, 224), color=(128, 128, 128))\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        label = row['label_idx']\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Enhanced but simple transforms\n",
    "def get_train_transforms(img_size=320):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.3),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.2),\n",
    "    ])\n",
    "\n",
    "def get_val_transforms(img_size=320):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model selection - simplified to avoid dependency issues\n",
    "def get_model(model_name='resnext', num_classes=20):\n",
    "    if model_name == 'resnext':\n",
    "        model = models.resnext50_32x4d(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        print(\"âœ… Using ResNeXt50\")\n",
    "    elif model_name == 'wide_resnet':\n",
    "        model = models.wide_resnet50_2(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        print(\"âœ… Using Wide ResNet50\")\n",
    "    else:\n",
    "        # Default: ResNet50\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        print(\"âœ… Using ResNet50\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b8b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Class-weighted loss\n",
    "class WeightedFocalLoss(nn.Module):\n",
    "    def __init__(self, class_weights=None, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(weight=self.class_weights, reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "        return torch.mean(focal_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate class weights\n",
    "def get_class_weights(df):\n",
    "    class_counts = df['label_idx'].value_counts().sort_index().values\n",
    "    total_samples = len(df)\n",
    "    class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "    return torch.FloatTensor(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c195d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training function\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for batch_idx, (imgs, labels) in enumerate(pbar):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += imgs.size(0)\n",
    "        \n",
    "        if batch_idx % 50 == 0:  # Update progress every 50 batches\n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}', \n",
    "                'Acc': f'{correct/total:.4f}',\n",
    "                'Batch': f'{batch_idx}/{len(loader)}'\n",
    "            })\n",
    "    \n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Validation function\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    preds_all, labels_all = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += imgs.size(0)\n",
    "            \n",
    "            preds_all.extend(preds.cpu().numpy())\n",
    "            labels_all.extend(labels.cpu().numpy())\n",
    "    \n",
    "    f1 = f1_score(labels_all, preds_all, average=\"micro\")\n",
    "    return total_loss / total, correct / total, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Main training loop\n",
    "def train_models():\n",
    "    # Use reliable torchvision models only\n",
    "    model_names = ['resnext', 'wide_resnet']  # Both better than ResNet50\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['label_idx'])):\n",
    "            print(f\"\\nğŸ”¥ Fold {fold+1}/{N_SPLITS}\")\n",
    "            \n",
    "            train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "            val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "            \n",
    "            print(f\"Train samples: {len(train_df)}, Val samples: {len(val_df)}\")\n",
    "            \n",
    "            # Create datasets\n",
    "            train_dataset = ImprovedDataset(train_df, TRAIN_DIR, get_train_transforms(IMG_SIZE))\n",
    "            val_dataset = ImprovedDataset(val_df, TRAIN_DIR, get_val_transforms(IMG_SIZE))\n",
    "            \n",
    "            # Create data loaders - simple approach\n",
    "            train_loader = DataLoader(\n",
    "                train_dataset, \n",
    "                batch_size=BATCH_SIZE, \n",
    "                shuffle=True,\n",
    "                num_workers=0,  # Set to 0 to avoid multiprocessing issues\n",
    "                pin_memory=True if DEVICE == 'cuda' else False\n",
    "            )\n",
    "            val_loader = DataLoader(\n",
    "                val_dataset, \n",
    "                batch_size=BATCH_SIZE, \n",
    "                shuffle=False,\n",
    "                num_workers=0,\n",
    "                pin_memory=True if DEVICE == 'cuda' else False\n",
    "            )\n",
    "            \n",
    "            # Model setup\n",
    "            model = get_model(model_name, num_classes).to(DEVICE)\n",
    "            \n",
    "            # Optimizer and scheduler\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "            \n",
    "            # Loss with class weights\n",
    "            class_weights = get_class_weights(train_df).to(DEVICE)\n",
    "            criterion = WeightedFocalLoss(class_weights=class_weights, alpha=1, gamma=2)\n",
    "            \n",
    "            # Training loop with early stopping\n",
    "            best_f1 = 0\n",
    "            patience = 5\n",
    "            patience_counter = 0\n",
    "            \n",
    "            print(\"Starting training...\")\n",
    "            for epoch in range(EPOCHS):\n",
    "                print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "                \n",
    "                # Train\n",
    "                train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "                \n",
    "                # Validate\n",
    "                val_loss, val_acc, val_f1 = validate(model, val_loader, criterion, DEVICE)\n",
    "                \n",
    "                # Step scheduler\n",
    "                scheduler.step()\n",
    "                \n",
    "                print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "                print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
    "                \n",
    "                # Save best model\n",
    "                if val_f1 > best_f1:\n",
    "                    best_f1 = val_f1\n",
    "                    patience_counter = 0\n",
    "                    torch.save(model.state_dict(), f\"{model_name}_fold{fold}_best.pth\")\n",
    "                    print(f\"âœ… New best F1: {best_f1:.4f}\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"â° Early stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "            \n",
    "            fold_scores.append(best_f1)\n",
    "            print(f\"\\nğŸ“Š Fold {fold+1} completed - Best F1: {best_f1:.4f}\")\n",
    "        \n",
    "        avg_score = np.mean(fold_scores)\n",
    "        std_score = np.std(fold_scores)\n",
    "        print(f\"\\nğŸ¯ {model_name} Results:\")\n",
    "        print(f\"Fold scores: {[f'{score:.4f}' for score in fold_scores]}\")\n",
    "        print(f\"Average F1: {avg_score:.4f} Â± {std_score:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ Starting improved training...\")\n",
    "    train_models()\n",
    "    print(\"\\nğŸ‰ Training completed!\")\n",
    "    print(\"ğŸ“ Model files saved with format: {model_name}_fold{fold}_best.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
